[0;32mStarting B200 Discovery Script (Verified Edition)[0m
Log file: /home/ubuntu/b200_discovery_192-9-185-148_20251218_205418.log
Started at: Thu Dec 18 20:54:18 UTC 2025
Running as: ubuntu


===============================================================================
  PHASE 1: QUICK SYSTEM SNAPSHOT
  2025-12-18 20:54:18
===============================================================================


--- Basic System Info ---

[CMD] Hostname: hostname
192-9-185-148

[CMD] Kernel: uname -a
Linux 192-9-185-148 6.11.0-1016-nvidia #16-Ubuntu SMP PREEMPT_DYNAMIC Sun Sep 21 17:06:33 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux

[CMD] OS Release: cat /etc/os-release
PRETTY_NAME="Ubuntu 24.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="24.04"
VERSION="24.04.3 LTS (Noble Numbat)"
VERSION_CODENAME=noble
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=noble
LOGO=ubuntu-logo

[CMD] Architecture: uname -m
x86_64

[CMD] Uptime: uptime
 20:54:18 up 6 min,  1 user,  load average: 0.11, 0.10, 0.06

[CMD] Current user: whoami
ubuntu

[CMD] User groups: groups
ubuntu adm cdrom sudo dip lxd


--- Quick GPU Check ---

[CMD] nvidia-smi overview: nvidia-smi
Thu Dec 18 20:54:18 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA B200                    On  |   00000000:07:00.0 Off |                    0 |
| N/A   30C    P0            144W / 1000W |       0MiB / 183359MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

[CMD] GPU count and names: nvidia-smi -L
GPU 0: NVIDIA B200 (UUID: GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3)


--- Memory Overview ---

[CMD] Memory: free -h
               total        used        free      shared  buff/cache   available
Mem:           354Gi       3.3Gi       352Gi       4.9Mi       1.0Gi       350Gi
Swap:             0B          0B          0B

[CMD] Swap: swapon --show


===============================================================================
  PHASE 2: B200 BLACKWELL CRITICAL CHECKS
  2025-12-18 20:54:18
===============================================================================


--- Driver Type Verification (B200 REQUIRES nvidia-open) ---

[CRITICAL] B200/Blackwell ONLY works with nvidia-open kernel modules
[CRITICAL] Proprietary driver does NOT support Blackwell architecture

[FILE] /proc/driver/nvidia/version:
NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  570.195.03  Release Build  (dvs-builder@U22-I3-H04-03-1)  Sat Sep 20 00:47:16 UTC 2025
GCC version:  gcc version 13.3.0 (Ubuntu 13.3.0-6ubuntu2~24.04) 

[CMD] Kernel modules (nvidia): lsmod
nvidia_modeset       1724416  0
video                  77824  1 nvidia_modeset
nvidia_uvm           2117632  0
nvidia_peermem         16384  0
nvidia              11653120  8 nvidia_uvm,nvidia_peermem,nvidia_modeset
ib_uverbs             200704  3 nvidia_peermem,rdma_ucm,mlx5_ib
filename:       /lib/modules/6.11.0-1016-nvidia/updates/dkms/nvidia.ko.zst
version:        570.195.03
license:        Dual MIT/GPL
[WARN] Could not confirm nvidia-open - B200 requires open kernel modules


--- Fabric Manager Status (REQUIRED for NVSwitch on B200) ---

[INFO] B200 HGX systems require Fabric Manager + NVLSM for NVSwitch operation

[SERVICE] nvidia-fabricmanager:
inactive
inactive/not found
‚óã nvidia-fabricmanager.service - NVIDIA fabric manager service
     Loaded: loaded (/usr/lib/systemd/system/nvidia-fabricmanager.service; disabled; preset: enabled)
     Active: inactive (dead)
[SKIP] Service not found

[SERVICE] nvidia-nvlsm:
inactive
inactive/not found
[SKIP] Service not found

[SERVICE] nvidia-persistenced:
active
‚óè nvidia-persistenced.service - NVIDIA Persistence Daemon
     Loaded: loaded (/usr/lib/systemd/system/nvidia-persistenced.service; enabled; preset: enabled)
     Active: active (running) since Thu 2025-12-18 20:48:35 UTC; 5min ago
    Process: 1854 ExecStart=/usr/bin/nvidia-persistenced --user nvidia-persistenced (code=exited, status=0/SUCCESS)
   Main PID: 1855 (nvidia-persiste)
      Tasks: 1 (limit: 434932)
     Memory: 1.8M (peak: 3.3M)
        CPU: 2.520s
     CGroup: /system.slice/nvidia-persistenced.service
             ‚îî‚îÄ1855 /usr/bin/nvidia-persistenced --user nvidia-persistenced

Dec 18 20:48:32 192-9-185-148 systemd[1]: Starting nvidia-persistenced.service - NVIDIA Persistence Daemon...
Dec 18 20:48:32 192-9-185-148 nvidia-persistenced[1855]: Started (1855)
Dec 18 20:48:35 192-9-185-148 systemd[1]: Started nvidia-persistenced.service - NVIDIA Persistence Daemon.

[CMD] Fabric Manager version: nv-fabricmanager --version
Fabric Manager version is : 570.195.03

[FILE] /usr/share/nvidia/nvswitch/fabricmanager.cfg:
# NVIDIA Fabric Manager configuration file.
# Note: This configuration file is read during Fabric Manager service startup. So, Fabric Manager 
# service restart is required for new settings to take effect.

#	Description: Fabric Manager logging levels
#	Possible Values:
#		0  - All the logging is disabled
#		1  - Set log level to CRITICAL and above
#		2  - Set log level to ERROR and above
#		3  - Set log level to WARNING and above
#		4  - Set log level to INFO and above
LOG_LEVEL=4

#	Description: Filename for Fabric Manager logs
#	Possible Values:
#       Full path/filename string (max length of 256). Logs will be redirected to console(stderr)
#       if the specified log file can't be opened or the path is empty.
LOG_FILE_NAME=/var/log/fabricmanager.log

#	Description: Append to an existing log file or overwrite the logs
#	Possible Values:
#		0  - No  (Log file will be overwritten)
#		1  - Yes (Append to existing log)
LOG_APPEND_TO_LOG=1

#	Description: Max size of log file (in MB)
#	Possible Values:
#		Any Integer values
LOG_FILE_MAX_SIZE=1024

#   Description: Number of times the FM log is rotated once it reaches LOG_FILE_MAX_SIZE
#   Possible Values:
#       0                - Log is not rotated. Logging is stopped once the FM log file reaches
#                          the size specified in LOG_FILE_MAX_SIZE
#       Non-zero Integer - Log is rotated upto the number of times specified in LOG_MAX_ROTATE_COUNT,
#                          after the size of the log file reaches the size specified in LOG_FILE_MAX_SIZE.
#                          Combined FM log size is LOG_FILE_MAX_SIZE multipled by LOG_MAX_ROTATE_COUNT+1
#                          Once this threshold is reached, the oldest log file is purged and reused.
LOG_MAX_ROTATE_COUNT=3

#	Description: Redirect all the logs to syslog instead of logging to file
#	Possible Values:
#		0  - No
#		1  - Yes
LOG_USE_SYSLOG=0

#	Description: daemonize Fabric Manager on start-up
#	Possible Values:
#       0  - No (Do not daemonize and run fabric manager as a normal process)
#       1  - Yes (Run Fabric Manager process as Unix daemon
DAEMONIZE=1

#	Description: Network interface to listen for Global and Local Fabric Manager communication
#	Possible Values:
#		A valid IPv4 address. By default, uses loopback (127.0.0.1) interface
#   Note: This is only effective on DGX A100, HGX A100, DGX H100, HGX H100 NVSwitch based systems
BIND_INTERFACE_IP=127.0.0.1

#	Description: Starting TCP port number for Global and Local Fabric Manager communication
#	Possible Values:
#		Any value between 0 and 65535
#   Note: This is only effective on DGX A100, HGX A100, DGX H100, HGX H100 NVSwitch based systems
STARTING_TCP_PORT=16000

#   Description: Use Unix sockets instead of TCP Socket for Global and Local Fabric Manager communication
#	Possible Values:
#		Unix domain socket path (max length of 256)
#	Default Value: 
#		Empty String (TCP socket will be used instead of Unix sockets)
#   Note: This is only effective on DGX A100, HGX A100, DGX H100, HGX H100 NVSwitch based systems
UNIX_SOCKET_PATH=

#	Description: Fabric Manager Operating Mode
#	Possible Values:
#       0  - Start Fabric Manager in Bare metal or Full pass through virtualization mode
#       1  - Start Fabric Manager in Shared NVSwitch multitenancy mode. 
#       2  - Start Fabric Manager in vGPU based multitenancy mode.
FABRIC_MODE=0

#	Description: Restart Fabric Manager after exit
#                On DGX A100, HGX A100, DGX H100, HGX H100 NVSwitch based systems, this is applicable only in Shared
#                NVSwitch or vGPU based multitenancy mode
#	Possible Values:
#       0  - Start Fabric Manager and follow full initialization sequence
#       1  - Start Fabric Manager and follow resiliency/restart sequence
FABRIC_MODE_RESTART=0

#	Description: Specify the filename to be used to save Fabric Manager states.
#                    Valid only if Shared NVSwitch or vGPU based multitenancy mode is enabled
#	Possible Values:
#	    Full path/filename string (max length of 256)
#   Note: This is only effective on DGX A100, HGX A100, DGX H100, HGX H100 NVSwitch based systems
STATE_FILE_NAME=/tmp/fabricmanager.state

#	Description: Network interface to listen for Fabric Manager SDK/API to communicate with running FM instance.
#	Possible Values:
#		A valid IPv4 address. By default, uses loopback (127.0.0.1) interface
FM_CMD_BIND_INTERFACE=127.0.0.1 

#	Description: TCP port number for Fabric Manager SDK/API to communicate with running FM instance.
#	Possible Values:
#		Any value between 0 and 65535
FM_CMD_PORT_NUMBER=6666

#	Description: Use Unix sockets instead of TCP Socket for Fabric Manager SDK/API communication
#	Possible Values:
#		Unix domain socket path (max length of 256)
#	Default Value: 
#		Empty String (TCP socket will be used instead of Unix sockets)
FM_CMD_UNIX_SOCKET_PATH=

#   Description: Fabric Manager does not exit when facing failures
#   Possible Values:
#       0 ‚Äì Fabric Manager service will terminate on errors such as, NVSwitch and GPU config failure, 
#           typical software errors etc.  
#       1 ‚Äì Fabric Manager service will stay running on errors such as, NVSwitch and GPU config failure, 
#           typical software errors etc. However, the system will be uninitialized and CUDA application 
#           launch will fail. 
FM_STAY_RESIDENT_ON_FAILURES=0

#   Description: Degraded Mode options when there is an Access Link Failure (GPU to NVSwitch NVLink failure)
#   Possible Values:
#       In bare metal or full passthrough virtualization mode
#       0  - Remove the GPU with the Access NVLink failure from NVLink P2P capability
#       1  - Disable the NVSwitch and its peer NVSwitch, which reduces NVLink P2P bandwidth
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#
#       In Shared NVSwitch or vGPU based multitenancy mode
#       0  - Disable partitions which are using the Access Link failed GPU
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#       1  - Disable the NVSwitch and its peer NVSwitch,
#            all partitions will be available but with reduced NVLink P2P bandwidth
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
ACCESS_LINK_FAILURE_MODE=0

#   Description: Degraded Mode options when there is a Trunk Link Failure (NVSwitch to NVSwitch NVLink failure)
#   Possible Values:
#       In bare metal or full passthrough virtualization mode
#       0  - Exit Fabric Manager and leave the system/NVLinks uninitialized
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#       1  - Disable the NVSwitch and its peer NVSwitch, which reduces NVLink P2P bandwidth
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#
#       In Shared NVSwitch or vGPU based multitenancy mode
#       0  - Remove partitions that are using the Trunk NVLinks
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#       1  - Disable the NVSwitch and its peer NVSwitch,
#            all partitions will be available but with reduced NVLink P2P bandwidth
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
TRUNK_LINK_FAILURE_MODE=0

#   Description: Degraded Mode options when there is a NVSwitch failure or an NVSwitch is excluded
#   Possible Values:
#       In bare metal or full passthrough virtualization mode
#       0  - Abort Fabric Manager
#       1  - Disable the NVSwitch and its peer NVSwitch, which reduces P2P bandwidth
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#
#       In Shared NVSwitch or vGPU based multitenancy mode
#       0  - Disable partitions that are using the NVSwitch
#            This is only effective on DGX A100 and HGX A100 NVSwitch based systems
#       1  - Disable the NVSwitch and its peer NVSwitch,
#            all partitions will be available but with reduced NVLink P2P bandwidth
#            Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
NVSWITCH_FAILURE_MODE=0

#	Description: Control running CUDA jobs behavior when Fabric Manager service is stopped or terminated
#	Possible Values:
#       0  - Do not abort running CUDA jobs when Fabric Manager exits. However new CUDA job launch will fail.
#       1  - Abort all running CUDA jobs when Fabric Manager exits.
#	Note: This is only effective on DGX A100 and HGX A100 NVSwitch based systems
ABORT_CUDA_JOBS_ON_FM_EXIT=1

#       Description: Absolute directory path containing Fabric Manager topology files
#       Possible Values:
#               A valid directory path string (max length of 256)
TOPOLOGY_FILE_PATH=/usr/share/nvidia/nvswitch

#   Description: Use RPC instead of raw sockets for communication between global and local fabric manager.
#   Possible values:
#       0 - Do not use RPCs
#       1 - Use RPC
USE_RPC=1

#  Description: Name of the network interface used for communication.
#               OPTIONAL - If empty, network interface will be determined by matching bind IP to
#                          node configuration file.  Only necessary to configure if the bind IP
#                          is present on multiple network interfaces.
#  Possible Values:
#      Interface names like eth0, ens32 .. etc
#  Default Value:
NETWORK_INTERFACE=


#  Description:  Enable authentication and encryption for RPC communication.
#                NOTE: If USE_RPC is 0, this is ignored.
#  Possible Values:
#      0:  Disable encryption and authentication
#      1:  Enable encryption and authentication
#  Default value: 0
ENABLE_AUTH_ENCRYPTION=0

#  Description:  This determines how fabric manager will try to retrieve the keys, certificates, and certificate
#                authority for authentication and encryption.
#                If ENABLE_AUTH_ENCRYPTION is enabled (1), then AUTH_SOURCE must be configured
#                as one of the supported values.  An empty or unexpected value will prevent initialization.
#                If USE_RPC is 0, this is ignored.
#  Possible Values:
#      FILE:      The provided values are paths to files on the file system.
#      ENV_PATH:  The provided values are environment variable names to retrieve, and the values in the
#                 environment variables are treated as paths to files on the file system.
#      ENV_VAL:   The provided values are environment variable names to retrieve, and the values in the
#                 environment variables are treated as the actual values for the key/cert/cert auth.
AUTH_SOURCE=

# Description:  These fields are interpreted based on how AUTH_SOURCE is configured
SERVER_KEY=
SERVER_CERT=
SERVER_CERT_AUTH=
CLIENT_KEY=
CLIENT_CERT=
CLIENT_CERT_AUTH=

#  Description:  Override the target hostname for authentication of the certificates and keys.  This allows
#                certificates with common names that do not match the ip addresses provided for the nodes.
#                Example:
#                  If the certificate has the subject:
#                    "/C=US/ST=CA/L=Santa Clara/O=NVIDIA/OU=Test/CN=localhost"
#                  The certificate validation will expect the connection hostname to be "localhost", by
#                  setting IMEX_SECURITY_TARGET_OVERRIDE=localhost you can cause override the connection
#                  hostname for security purposes to be "localhost", allowing the connection to succeed.
#                If USE_RPC is 0, this is ignored.
SECURITY_TARGET_OVERRIDE=

#  Description: This tunable determines the domain behavior in case the trunk links are down or experience
#               fatal errors. When MNNVL_RESILIENCY_MODE is set to 0, in case a single trunk link fails, the
#               inter-node traffic between the impacted L1 switch node and the rest of the domain will be
#               unavailable. When MNNVL_RESILIENCY_MODE is set to 1, the domain can sustain up to failures
#               of half (excluded) of the trunk links on an L1 switch before the inter-node traffic between
#               this L1 switch node and the rest of the domain becomes unavailable.
MNNVL_RESILIENCY_MODE=0

#	Description: Determine whether a default partition needs to be created
#	Possible Values:
#       0             - No partitions are created during GFM initialization. GFM disables routing until an API request 
#                     to create a partition is successful.
#       1(default)    - Creates a default partition during GFM initialization. GFM creates the partition to include
#                     all GPUs in the topology and enables routing so that all GPUs can communicate to each other.
    
MNNVL_ENABLE_DEFAULT_PARTITION=1


--- Driver and CUDA Version Check ---

[INFO] B200 requires: Driver 570.133.20+, CUDA 12.8+ for SM_100

[CMD] nvidia-smi driver info: nvidia-smi --query-gpu=driver_version --format=csv,noheader
[CMD] CUDA version from nvidia-smi: nvidia-smi --query-gpu=name,driver_version --format=csv
name, driver_version
[CMD] nvcc version: nvcc --version
[SKIP] Command not found: nvcc


===============================================================================
  PHASE 3: DEEP GPU ANALYSIS
  2025-12-18 20:54:18
===============================================================================


--- Full GPU Query ---

[CMD] nvidia-smi full query: nvidia-smi -q

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:18 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    Product Name                          : NVIDIA B200
    Product Brand                         : NVIDIA
    Product Architecture                  : Blackwell
    Display Mode                          : Disabled
    Display Active                        : Disabled
    Persistence Mode                      : Enabled
    Addressing Mode                       : HMM
    MIG Mode
        Current                           : Disabled
        Pending                           : Disabled
    Accounting Mode                       : Disabled
    Accounting Mode Buffer Size           : 4000
    Driver Model
        Current                           : N/A
        Pending                           : N/A
    Serial Number                         : 1655024042513
    GPU UUID                              : GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3
    Minor Number                          : 0
    VBIOS Version                         : 97.00.9A.00.0F
    MultiGPU Board                        : No
    Board ID                              : 0x700
    Board Part Number                     : 692-2G525-0220-000
    GPU Part Number                       : 2901-886-A1
    FRU Part Number                       : N/A
    Platform Info
        Chassis Serial Number             : 
        Slot Number                       : N/A
        Tray Index                        : N/A
        Host ID                           : 1
        Peer Type                         : Switch Connected
        Module Id                         : 7
        GPU Fabric GUID                   : 0xbe3b659b89058095
    Inforom Version
        Image Version                     : G525.0220.00.03
        OEM Object                        : 2.1
        ECC Object                        : 7.16
        Power Management Object           : N/A
    Inforom BBX Object Flush
        Latest Timestamp                  : N/A
        Latest Duration                   : N/A
    GPU Operation Mode
        Current                           : N/A
        Pending                           : N/A
    GPU C2C Mode                          : Disabled
    GPU Virtualization Mode
        Virtualization Mode               : Pass-Through
        Host VGPU Mode                    : N/A
        vGPU Heterogeneous Mode           : N/A
    GPU Reset Status
        Reset Required                    : Requested functionality has been deprecated
        Drain and Reset Recommended       : Requested functionality has been deprecated
    GPU Recovery Action                   : None
    GSP Firmware Version                  : 570.195.03
    IBMNPU
        Relaxed Ordering Mode             : N/A
    PCI
        Bus                               : 0x07
        Device                            : 0x00
        Domain                            : 0x0000
        Base Classcode                    : 0x3
        Sub Classcode                     : 0x2
        Device Id                         : 0x290110DE
        Bus Id                            : 00000000:07:00.0
        Sub System Id                     : 0x199910DE
        GPU Link Info
            PCIe Generation
                Max                       : 5
                Current                   : 5
                Device Current            : 5
                Device Max                : 5
                Host Max                  : N/A
            Link Width
                Max                       : 16x
                Current                   : 16x
        Bridge Chip
            Type                          : N/A
            Firmware                      : N/A
        Replays Since Reset               : 0
        Replay Number Rollovers           : 0
        Tx Throughput                     : 805 KB/s
        Rx Throughput                     : 767 KB/s
        Atomic Caps Outbound              : FETCHADD_32 FETCHADD_64 SWAP_32 SWAP_64 CAS_32 CAS_64 
        Atomic Caps Inbound               : FETCHADD_32 FETCHADD_64 SWAP_32 SWAP_64 CAS_32 CAS_64 
    Fan Speed                             : N/A
    Performance State                     : P0
    Clocks Event Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    Sparse Operation Mode                 : N/A
    FB Memory Usage
        Total                             : 183359 MiB
        Reserved                          : 718 MiB
        Used                              : 0 MiB
        Free                              : 182642 MiB
    BAR1 Memory Usage
        Total                             : 262144 MiB
        Used                              : 1 MiB
        Free                              : 262143 MiB
    Conf Compute Protected Memory Usage
        Total                             : 0 MiB
        Used                              : 0 MiB
        Free                              : 0 MiB
    Compute Mode                          : Default
    Utilization
        GPU                               : 0 %
        Memory                            : 0 %
        Encoder                           : 0 %
        Decoder                           : 0 %
        JPEG                              : 0 %
        OFA                               : 0 %
    Encoder Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    FBC Stats
        Active Sessions                   : 0
        Average FPS                       : 0
        Average Latency                   : 0
    DRAM Encryption Mode
        Current                           : N/A
        Pending                           : N/A
    ECC Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            SRAM Correctable              : 0
            SRAM Uncorrectable Parity     : 0
            SRAM Uncorrectable SEC-DED    : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
        Aggregate
            SRAM Correctable              : 0
            SRAM Uncorrectable Parity     : 0
            SRAM Uncorrectable SEC-DED    : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
            SRAM Threshold Exceeded       : No
        Aggregate Uncorrectable SRAM Sources
            SRAM L2                       : 0
            SRAM SM                       : 0
            SRAM Microcontroller          : 0
            SRAM PCIE                     : 0
            SRAM Other                    : 0
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A
    Remapped Rows
        Correctable Error                 : 0
        Uncorrectable Error               : 0
        Pending                           : No
        Remapping Failure Occurred        : No
        Bank Remap Availability Histogram
            Max                           : 3840 bank(s)
            High                          : 0 bank(s)
            Partial                       : 0 bank(s)
            Low                           : 0 bank(s)
            None                          : 0 bank(s)
    Temperature
        GPU Current Temp                  : 30 C
        GPU T.Limit Temp                  : 58 C
        GPU Shutdown T.Limit Temp         : -5 C
        GPU Slowdown T.Limit Temp         : -3 C
        GPU Max Operating T.Limit Temp    : 0 C
        GPU Target Temperature            : N/A
        Memory Current Temp               : 30 C
        Memory Max Operating T.Limit Temp : 0 C
    GPU Power Readings
        Average Power Draw                : 146.22 W
        Instantaneous Power Draw          : 185.59 W
        Current Power Limit               : 1000.00 W
        Requested Power Limit             : 1000.00 W
        Default Power Limit               : 1000.00 W
        Min Power Limit                   : 200.00 W
        Max Power Limit                   : 1000.00 W
    GPU Memory Power Readings 
        Average Power Draw                : 18.27 W
        Instantaneous Power Draw          : N/A
    Module Power Readings
        Average Power Draw                : N/A
        Instantaneous Power Draw          : N/A
        Current Power Limit               : N/A
        Requested Power Limit             : N/A
        Default Power Limit               : N/A
        Min Power Limit                   : N/A
        Max Power Limit                   : N/A
    Power Smoothing                       : Insufficient Permissions
    Workload Power Profiles
        Requested Profiles                : N/A
        Enforced Profiles                 : N/A
    Clocks
        Graphics                          : 120 MHz
        SM                                : 120 MHz
        Memory                            : 3996 MHz
        Video                             : 600 MHz
    Applications Clocks
        Graphics                          : 1965 MHz
        Memory                            : 3996 MHz
    Default Applications Clocks
        Graphics                          : 1965 MHz
        Memory                            : 3996 MHz
    Deferred Clocks
        Memory                            : N/A
    Max Clocks
        Graphics                          : 1965 MHz
        SM                                : 1965 MHz
        Memory                            : 3996 MHz
        Video                             : 1965 MHz
    Max Customer Boost Clocks
        Graphics                          : 1965 MHz
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A
    Voltage
        Graphics                          : N/A
    Fabric
        State                             : Completed
        Status                            : Success
        CliqueId                          : 0
        ClusterUUID                       : 00000000-0000-0000-0000-000000000000
        Health
            Bandwidth                     : N/A
            Route Recovery in progress    : N/A
            Route Unhealthy               : N/A
            Access Timeout Recovery       : False
    Processes                             : None
    Capabilities
        EGM                               : disabled



--- GPU Topology (NVLink 5.0 / NVSwitch 4.0) ---

[INFO] B200 NVLink 5.0: 18 links per GPU, 50GB/s per link, 1.8TB/s total
[INFO] HGX B200: 2 NVSwitch chips + 8 GPUs, 9 NVLinks per GPU to each switch

[CMD] Topology matrix: nvidia-smi topo -m
	[4mGPU0	NIC0	CPU Affinity	NUMA Affinity	GPU NUMA ID[0m
GPU0	 X 	PHB	0-25	0		N/A
NIC0	PHB	 X 				

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks

NIC Legend:

  NIC0: mlx5_0


[CMD] Topology with PCIe: nvidia-smi topo -mp
	[4mGPU0	NIC0	CPU Affinity	NUMA Affinity	GPU NUMA ID[0m
GPU0	 X 	PHB	0-25	0		N/A
NIC0	PHB	 X 				

Legend:

  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge

NIC Legend:

  NIC0: mlx5_0



--- NVLink Status (Critical for B200 Performance) ---

[CMD] NVLink status: nvidia-smi nvlink -s
GPU 0: NVIDIA B200 (UUID: GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3)
	 Link 0: 50 GB/s
	 Link 1: 50 GB/s
	 Link 2: 50 GB/s
	 Link 3: 50 GB/s
	 Link 4: 50 GB/s
	 Link 5: 50 GB/s
	 Link 6: 50 GB/s
	 Link 7: 50 GB/s
	 Link 8: 50 GB/s
	 Link 9: 50 GB/s
	 Link 10: 50 GB/s
	 Link 11: 50 GB/s
	 Link 12: 50 GB/s
	 Link 13: 50 GB/s
	 Link 14: 50 GB/s
	 Link 15: 50 GB/s
	 Link 16: 50 GB/s
	 Link 17: 50 GB/s

[CMD] NVLink capabilities: nvidia-smi nvlink -c
GPU 0: NVIDIA B200 (UUID: GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3)
	 Link 0, P2P is supported: true
	 Link 0, Access to system memory supported: true
	 Link 0, P2P atomics supported: true
	 Link 0, System memory atomics supported: true
	 Link 0, SLI is supported: true
	 Link 0, Link is supported: true
	 Link 1, P2P is supported: true
	 Link 1, Access to system memory supported: true
	 Link 1, P2P atomics supported: true
	 Link 1, System memory atomics supported: true
	 Link 1, SLI is supported: true
	 Link 1, Link is supported: true
	 Link 2, P2P is supported: true
	 Link 2, Access to system memory supported: true
	 Link 2, P2P atomics supported: true
	 Link 2, System memory atomics supported: true
	 Link 2, SLI is supported: true
	 Link 2, Link is supported: true
	 Link 3, P2P is supported: true
	 Link 3, Access to system memory supported: true
	 Link 3, P2P atomics supported: true
	 Link 3, System memory atomics supported: true
	 Link 3, SLI is supported: true
	 Link 3, Link is supported: true
	 Link 4, P2P is supported: true
	 Link 4, Access to system memory supported: true
	 Link 4, P2P atomics supported: true
	 Link 4, System memory atomics supported: true
	 Link 4, SLI is supported: true
	 Link 4, Link is supported: true
	 Link 5, P2P is supported: true
	 Link 5, Access to system memory supported: true
	 Link 5, P2P atomics supported: true
	 Link 5, System memory atomics supported: true
	 Link 5, SLI is supported: true
	 Link 5, Link is supported: true
	 Link 6, P2P is supported: true
	 Link 6, Access to system memory supported: true
	 Link 6, P2P atomics supported: true
	 Link 6, System memory atomics supported: true
	 Link 6, SLI is supported: true
	 Link 6, Link is supported: true
	 Link 7, P2P is supported: true
	 Link 7, Access to system memory supported: true
	 Link 7, P2P atomics supported: true
	 Link 7, System memory atomics supported: true
	 Link 7, SLI is supported: true
	 Link 7, Link is supported: true
	 Link 8, P2P is supported: true
	 Link 8, Access to system memory supported: true
	 Link 8, P2P atomics supported: true
	 Link 8, System memory atomics supported: true
	 Link 8, SLI is supported: true
	 Link 8, Link is supported: true
	 Link 9, P2P is supported: true
	 Link 9, Access to system memory supported: true
	 Link 9, P2P atomics supported: true
	 Link 9, System memory atomics supported: true
	 Link 9, SLI is supported: true
	 Link 9, Link is supported: true
	 Link 10, P2P is supported: true
	 Link 10, Access to system memory supported: true
	 Link 10, P2P atomics supported: true
	 Link 10, System memory atomics supported: true
	 Link 10, SLI is supported: true
	 Link 10, Link is supported: true
	 Link 11, P2P is supported: true
	 Link 11, Access to system memory supported: true
	 Link 11, P2P atomics supported: true
	 Link 11, System memory atomics supported: true
	 Link 11, SLI is supported: true
	 Link 11, Link is supported: true
	 Link 12, P2P is supported: true
	 Link 12, Access to system memory supported: true
	 Link 12, P2P atomics supported: true
	 Link 12, System memory atomics supported: true
	 Link 12, SLI is supported: true
	 Link 12, Link is supported: true
	 Link 13, P2P is supported: true
	 Link 13, Access to system memory supported: true
	 Link 13, P2P atomics supported: true
	 Link 13, System memory atomics supported: true
	 Link 13, SLI is supported: true
	 Link 13, Link is supported: true
	 Link 14, P2P is supported: true
	 Link 14, Access to system memory supported: true
	 Link 14, P2P atomics supported: true
	 Link 14, System memory atomics supported: true
	 Link 14, SLI is supported: true
	 Link 14, Link is supported: true
	 Link 15, P2P is supported: true
	 Link 15, Access to system memory supported: true
	 Link 15, P2P atomics supported: true
	 Link 15, System memory atomics supported: true
	 Link 15, SLI is supported: true
	 Link 15, Link is supported: true
	 Link 16, P2P is supported: true
	 Link 16, Access to system memory supported: true
	 Link 16, P2P atomics supported: true
	 Link 16, System memory atomics supported: true
	 Link 16, SLI is supported: true
	 Link 16, Link is supported: true
	 Link 17, P2P is supported: true
	 Link 17, Access to system memory supported: true
	 Link 17, P2P atomics supported: true
	 Link 17, System memory atomics supported: true
	 Link 17, SLI is supported: true
	 Link 17, Link is supported: true

[CMD] NVLink error counters: nvidia-smi nvlink -e
GPU 0: NVIDIA B200 (UUID: GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3)
	 Link 0: Tx packets: 202
	 Link 0: Tx bytes: 58176
	 Link 0: Rx packets: 202
	 Link 0: Rx bytes: 58176
	 Link 0: Malformed packet Errors: 0
	 Link 0: Buffer overrun Errors: 0
	 Link 0: Rx Errors: 0
	 Link 0: Rx remote Errors: 0
	 Link 0: Rx General Errors: 0
	 Link 0: Local link integrity Errors: 0
	 Link 0: Tx discards: 0
	 Link 0: Link recovery successful events: 0
	 Link 0: Link recovery failed events: 0
	 Link 0: Total link recovery events: 0
	 Link 0: Effective Errors: 0
	 Link 0: Effective BER: 15e-255
	 Link 0: Symbol Errors: 0
	 Link 0: Symbol BER: 15e-255
	 Link 0: FEC Errors - 0: 2145917356
	 Link 0: FEC Errors - 1: 0
	 Link 0: FEC Errors - 2: 0
	 Link 0: FEC Errors - 3: 0
	 Link 0: FEC Errors - 4: 0
	 Link 0: FEC Errors - 5: 0
	 Link 0: FEC Errors - 6: 0
	 Link 0: FEC Errors - 7: 0
	 Link 0: FEC Errors - 8: 0
	 Link 0: FEC Errors - 9: 0
	 Link 0: FEC Errors - 10: 0
	 Link 0: FEC Errors - 11: 0
	 Link 0: FEC Errors - 12: 0
	 Link 0: FEC Errors - 13: 0
	 Link 0: FEC Errors - 14: 0
	 Link 0: FEC Errors - 15: 0

	 Link 1: Tx packets: 120
	 Link 1: Tx bytes: 34560
	 Link 1: Rx packets: 120
	 Link 1: Rx bytes: 34560
	 Link 1: Malformed packet Errors: 0
	 Link 1: Buffer overrun Errors: 0
	 Link 1: Rx Errors: 0
	 Link 1: Rx remote Errors: 0
	 Link 1: Rx General Errors: 0
	 Link 1: Local link integrity Errors: 0
	 Link 1: Tx discards: 0
	 Link 1: Link recovery successful events: 0
	 Link 1: Link recovery failed events: 0
	 Link 1: Total link recovery events: 0
	 Link 1: Effective Errors: 0
	 Link 1: Effective BER: 15e-255
	 Link 1: Symbol Errors: 0
	 Link 1: Symbol BER: 15e-255
	 Link 1: FEC Errors - 0: 2097781762
	 Link 1: FEC Errors - 1: 2
	 Link 1: FEC Errors - 2: 0
	 Link 1: FEC Errors - 3: 0
	 Link 1: FEC Errors - 4: 0
	 Link 1: FEC Errors - 5: 0
	 Link 1: FEC Errors - 6: 0
	 Link 1: FEC Errors - 7: 0
	 Link 1: FEC Errors - 8: 0
	 Link 1: FEC Errors - 9: 0
	 Link 1: FEC Errors - 10: 0
	 Link 1: FEC Errors - 11: 0
	 Link 1: FEC Errors - 12: 0
	 Link 1: FEC Errors - 13: 0
	 Link 1: FEC Errors - 14: 0
	 Link 1: FEC Errors - 15: 0

	 Link 2: Tx packets: 163
	 Link 2: Tx bytes: 46944
	 Link 2: Rx packets: 160
	 Link 2: Rx bytes: 46080
	 Link 2: Malformed packet Errors: 0
	 Link 2: Buffer overrun Errors: 0
	 Link 2: Rx Errors: 0
	 Link 2: Rx remote Errors: 0
	 Link 2: Rx General Errors: 0
	 Link 2: Local link integrity Errors: 0
	 Link 2: Tx discards: 0
	 Link 2: Link recovery successful events: 0
	 Link 2: Link recovery failed events: 0
	 Link 2: Total link recovery events: 0
	 Link 2: Effective Errors: 0
	 Link 2: Effective BER: 15e-255
	 Link 2: Symbol Errors: 0
	 Link 2: Symbol BER: 15e-255
	 Link 2: FEC Errors - 0: 2145750582
	 Link 2: FEC Errors - 1: 20
	 Link 2: FEC Errors - 2: 0
	 Link 2: FEC Errors - 3: 0
	 Link 2: FEC Errors - 4: 0
	 Link 2: FEC Errors - 5: 0
	 Link 2: FEC Errors - 6: 0
	 Link 2: FEC Errors - 7: 0
	 Link 2: FEC Errors - 8: 0
	 Link 2: FEC Errors - 9: 0
	 Link 2: FEC Errors - 10: 0
	 Link 2: FEC Errors - 11: 0
	 Link 2: FEC Errors - 12: 0
	 Link 2: FEC Errors - 13: 0
	 Link 2: FEC Errors - 14: 0
	 Link 2: FEC Errors - 15: 0

	 Link 3: Tx packets: 128
	 Link 3: Tx bytes: 36864
	 Link 3: Rx packets: 128
	 Link 3: Rx bytes: 36864
	 Link 3: Malformed packet Errors: 0
	 Link 3: Buffer overrun Errors: 0
	 Link 3: Rx Errors: 0
	 Link 3: Rx remote Errors: 0
	 Link 3: Rx General Errors: 0
	 Link 3: Local link integrity Errors: 0
	 Link 3: Tx discards: 0
	 Link 3: Link recovery successful events: 0
	 Link 3: Link recovery failed events: 0
	 Link 3: Total link recovery events: 0
	 Link 3: Effective Errors: 0
	 Link 3: Effective BER: 15e-255
	 Link 3: Symbol Errors: 0
	 Link 3: Symbol BER: 15e-255
	 Link 3: FEC Errors - 0: 2102395992
	 Link 3: FEC Errors - 1: 0
	 Link 3: FEC Errors - 2: 0
	 Link 3: FEC Errors - 3: 0
	 Link 3: FEC Errors - 4: 0
	 Link 3: FEC Errors - 5: 0
	 Link 3: FEC Errors - 6: 0
	 Link 3: FEC Errors - 7: 0
	 Link 3: FEC Errors - 8: 0
	 Link 3: FEC Errors - 9: 0
	 Link 3: FEC Errors - 10: 0
	 Link 3: FEC Errors - 11: 0
	 Link 3: FEC Errors - 12: 0
	 Link 3: FEC Errors - 13: 0
	 Link 3: FEC Errors - 14: 0
	 Link 3: FEC Errors - 15: 0

	 Link 4: Tx packets: 120
	 Link 4: Tx bytes: 34560
	 Link 4: Rx packets: 120
	 Link 4: Rx bytes: 34560
	 Link 4: Malformed packet Errors: 0
	 Link 4: Buffer overrun Errors: 0
	 Link 4: Rx Errors: 0
	 Link 4: Rx remote Errors: 0
	 Link 4: Rx General Errors: 0
	 Link 4: Local link integrity Errors: 0
	 Link 4: Tx discards: 0
	 Link 4: Link recovery successful events: 0
	 Link 4: Link recovery failed events: 0
	 Link 4: Total link recovery events: 0
	 Link 4: Effective Errors: 0
	 Link 4: Effective BER: 15e-255
	 Link 4: Symbol Errors: 0
	 Link 4: Symbol BER: 15e-255
	 Link 4: FEC Errors - 0: 2097931840
	 Link 4: FEC Errors - 1: 0
	 Link 4: FEC Errors - 2: 0
	 Link 4: FEC Errors - 3: 0
	 Link 4: FEC Errors - 4: 0
	 Link 4: FEC Errors - 5: 0
	 Link 4: FEC Errors - 6: 0
	 Link 4: FEC Errors - 7: 0
	 Link 4: FEC Errors - 8: 0
	 Link 4: FEC Errors - 9: 0
	 Link 4: FEC Errors - 10: 0
	 Link 4: FEC Errors - 11: 0
	 Link 4: FEC Errors - 12: 0
	 Link 4: FEC Errors - 13: 0
	 Link 4: FEC Errors - 14: 0
	 Link 4: FEC Errors - 15: 0

	 Link 5: Tx packets: 128
	 Link 5: Tx bytes: 36864
	 Link 5: Rx packets: 128
	 Link 5: Rx bytes: 36864
	 Link 5: Malformed packet Errors: 0
	 Link 5: Buffer overrun Errors: 0
	 Link 5: Rx Errors: 0
	 Link 5: Rx remote Errors: 0
	 Link 5: Rx General Errors: 0
	 Link 5: Local link integrity Errors: 0
	 Link 5: Tx discards: 0
	 Link 5: Link recovery successful events: 0
	 Link 5: Link recovery failed events: 0
	 Link 5: Total link recovery events: 0
	 Link 5: Effective Errors: 0
	 Link 5: Effective BER: 15e-255
	 Link 5: Symbol Errors: 0
	 Link 5: Symbol BER: 15e-255
	 Link 5: FEC Errors - 0: 2119237812
	 Link 5: FEC Errors - 1: 2
	 Link 5: FEC Errors - 2: 0
	 Link 5: FEC Errors - 3: 0
	 Link 5: FEC Errors - 4: 0
	 Link 5: FEC Errors - 5: 0
	 Link 5: FEC Errors - 6: 0
	 Link 5: FEC Errors - 7: 0
	 Link 5: FEC Errors - 8: 0
	 Link 5: FEC Errors - 9: 0
	 Link 5: FEC Errors - 10: 0
	 Link 5: FEC Errors - 11: 0
	 Link 5: FEC Errors - 12: 0
	 Link 5: FEC Errors - 13: 0
	 Link 5: FEC Errors - 14: 0
	 Link 5: FEC Errors - 15: 0

	 Link 6: Tx packets: 120
	 Link 6: Tx bytes: 34560
	 Link 6: Rx packets: 120
	 Link 6: Rx bytes: 34560
	 Link 6: Malformed packet Errors: 0
	 Link 6: Buffer overrun Errors: 0
	 Link 6: Rx Errors: 0
	 Link 6: Rx remote Errors: 0
	 Link 6: Rx General Errors: 0
	 Link 6: Local link integrity Errors: 0
	 Link 6: Tx discards: 0
	 Link 6: Link recovery successful events: 0
	 Link 6: Link recovery failed events: 0
	 Link 6: Total link recovery events: 0
	 Link 6: Effective Errors: 0
	 Link 6: Effective BER: 15e-255
	 Link 6: Symbol Errors: 0
	 Link 6: Symbol BER: 15e-255
	 Link 6: FEC Errors - 0: 2097954642
	 Link 6: FEC Errors - 1: 0
	 Link 6: FEC Errors - 2: 0
	 Link 6: FEC Errors - 3: 0
	 Link 6: FEC Errors - 4: 0
	 Link 6: FEC Errors - 5: 0
	 Link 6: FEC Errors - 6: 0
	 Link 6: FEC Errors - 7: 0
	 Link 6: FEC Errors - 8: 0
	 Link 6: FEC Errors - 9: 0
	 Link 6: FEC Errors - 10: 0
	 Link 6: FEC Errors - 11: 0
	 Link 6: FEC Errors - 12: 0
	 Link 6: FEC Errors - 13: 0
	 Link 6: FEC Errors - 14: 0
	 Link 6: FEC Errors - 15: 0

	 Link 7: Tx packets: 128
	 Link 7: Tx bytes: 36864
	 Link 7: Rx packets: 128
	 Link 7: Rx bytes: 36864
	 Link 7: Malformed packet Errors: 0
	 Link 7: Buffer overrun Errors: 0
	 Link 7: Rx Errors: 0
	 Link 7: Rx remote Errors: 0
	 Link 7: Rx General Errors: 0
	 Link 7: Local link integrity Errors: 0
	 Link 7: Tx discards: 0
	 Link 7: Link recovery successful events: 0
	 Link 7: Link recovery failed events: 0
	 Link 7: Total link recovery events: 0
	 Link 7: Effective Errors: 0
	 Link 7: Effective BER: 15e-255
	 Link 7: Symbol Errors: 0
	 Link 7: Symbol BER: 15e-255
	 Link 7: FEC Errors - 0: 2121913714
	 Link 7: FEC Errors - 1: 2
	 Link 7: FEC Errors - 2: 0
	 Link 7: FEC Errors - 3: 0
	 Link 7: FEC Errors - 4: 0
	 Link 7: FEC Errors - 5: 0
	 Link 7: FEC Errors - 6: 0
	 Link 7: FEC Errors - 7: 0
	 Link 7: FEC Errors - 8: 0
	 Link 7: FEC Errors - 9: 0
	 Link 7: FEC Errors - 10: 0
	 Link 7: FEC Errors - 11: 0
	 Link 7: FEC Errors - 12: 0
	 Link 7: FEC Errors - 13: 0
	 Link 7: FEC Errors - 14: 0
	 Link 7: FEC Errors - 15: 0

	 Link 8: Tx packets: 128
	 Link 8: Tx bytes: 36864
	 Link 8: Rx packets: 128
	 Link 8: Rx bytes: 36864
	 Link 8: Malformed packet Errors: 0
	 Link 8: Buffer overrun Errors: 0
	 Link 8: Rx Errors: 0
	 Link 8: Rx remote Errors: 0
	 Link 8: Rx General Errors: 0
	 Link 8: Local link integrity Errors: 0
	 Link 8: Tx discards: 0
	 Link 8: Link recovery successful events: 0
	 Link 8: Link recovery failed events: 0
	 Link 8: Total link recovery events: 0
	 Link 8: Effective Errors: 0
	 Link 8: Effective BER: 15e-255
	 Link 8: Symbol Errors: 0
	 Link 8: Symbol BER: 15e-255
	 Link 8: FEC Errors - 0: 2115121209
	 Link 8: FEC Errors - 1: 25
	 Link 8: FEC Errors - 2: 0
	 Link 8: FEC Errors - 3: 0
	 Link 8: FEC Errors - 4: 0
	 Link 8: FEC Errors - 5: 0
	 Link 8: FEC Errors - 6: 0
	 Link 8: FEC Errors - 7: 0
	 Link 8: FEC Errors - 8: 0
	 Link 8: FEC Errors - 9: 0
	 Link 8: FEC Errors - 10: 0
	 Link 8: FEC Errors - 11: 0
	 Link 8: FEC Errors - 12: 0
	 Link 8: FEC Errors - 13: 0
	 Link 8: FEC Errors - 14: 0
	 Link 8: FEC Errors - 15: 0

	 Link 9: Tx packets: 120
	 Link 9: Tx bytes: 34560
	 Link 9: Rx packets: 120
	 Link 9: Rx bytes: 34560
	 Link 9: Malformed packet Errors: 0
	 Link 9: Buffer overrun Errors: 0
	 Link 9: Rx Errors: 0
	 Link 9: Rx remote Errors: 0
	 Link 9: Rx General Errors: 0
	 Link 9: Local link integrity Errors: 0
	 Link 9: Tx discards: 0
	 Link 9: Link recovery successful events: 0
	 Link 9: Link recovery failed events: 0
	 Link 9: Total link recovery events: 0
	 Link 9: Effective Errors: 0
	 Link 9: Effective BER: 15e-255
	 Link 9: Symbol Errors: 0
	 Link 9: Symbol BER: 15e-255
	 Link 9: FEC Errors - 0: 2103486582
	 Link 9: FEC Errors - 1: 20
	 Link 9: FEC Errors - 2: 4
	 Link 9: FEC Errors - 3: 0
	 Link 9: FEC Errors - 4: 0
	 Link 9: FEC Errors - 5: 0
	 Link 9: FEC Errors - 6: 0
	 Link 9: FEC Errors - 7: 0
	 Link 9: FEC Errors - 8: 0
	 Link 9: FEC Errors - 9: 0
	 Link 9: FEC Errors - 10: 0
	 Link 9: FEC Errors - 11: 0
	 Link 9: FEC Errors - 12: 0
	 Link 9: FEC Errors - 13: 0
	 Link 9: FEC Errors - 14: 0
	 Link 9: FEC Errors - 15: 0

	 Link 10: Tx packets: 128
	 Link 10: Tx bytes: 36864
	 Link 10: Rx packets: 128
	 Link 10: Rx bytes: 36864
	 Link 10: Malformed packet Errors: 0
	 Link 10: Buffer overrun Errors: 0
	 Link 10: Rx Errors: 0
	 Link 10: Rx remote Errors: 0
	 Link 10: Rx General Errors: 0
	 Link 10: Local link integrity Errors: 0
	 Link 10: Tx discards: 0
	 Link 10: Link recovery successful events: 0
	 Link 10: Link recovery failed events: 0
	 Link 10: Total link recovery events: 0
	 Link 10: Effective Errors: 0
	 Link 10: Effective BER: 15e-255
	 Link 10: Symbol Errors: 0
	 Link 10: Symbol BER: 15e-255
	 Link 10: FEC Errors - 0: 2116164766
	 Link 10: FEC Errors - 1: 0
	 Link 10: FEC Errors - 2: 0
	 Link 10: FEC Errors - 3: 0
	 Link 10: FEC Errors - 4: 0
	 Link 10: FEC Errors - 5: 0
	 Link 10: FEC Errors - 6: 0
	 Link 10: FEC Errors - 7: 0
	 Link 10: FEC Errors - 8: 0
	 Link 10: FEC Errors - 9: 0
	 Link 10: FEC Errors - 10: 0
	 Link 10: FEC Errors - 11: 0
	 Link 10: FEC Errors - 12: 0
	 Link 10: FEC Errors - 13: 0
	 Link 10: FEC Errors - 14: 0
	 Link 10: FEC Errors - 15: 0

	 Link 11: Tx packets: 120
	 Link 11: Tx bytes: 34560
	 Link 11: Rx packets: 120
	 Link 11: Rx bytes: 34560
	 Link 11: Malformed packet Errors: 0
	 Link 11: Buffer overrun Errors: 0
	 Link 11: Rx Errors: 0
	 Link 11: Rx remote Errors: 0
	 Link 11: Rx General Errors: 0
	 Link 11: Local link integrity Errors: 0
	 Link 11: Tx discards: 0
	 Link 11: Link recovery successful events: 0
	 Link 11: Link recovery failed events: 0
	 Link 11: Total link recovery events: 0
	 Link 11: Effective Errors: 0
	 Link 11: Effective BER: 15e-255
	 Link 11: Symbol Errors: 0
	 Link 11: Symbol BER: 15e-255
	 Link 11: FEC Errors - 0: 2093672376
	 Link 11: FEC Errors - 1: 0
	 Link 11: FEC Errors - 2: 0
	 Link 11: FEC Errors - 3: 0
	 Link 11: FEC Errors - 4: 0
	 Link 11: FEC Errors - 5: 0
	 Link 11: FEC Errors - 6: 0
	 Link 11: FEC Errors - 7: 0
	 Link 11: FEC Errors - 8: 0
	 Link 11: FEC Errors - 9: 0
	 Link 11: FEC Errors - 10: 0
	 Link 11: FEC Errors - 11: 0
	 Link 11: FEC Errors - 12: 0
	 Link 11: FEC Errors - 13: 0
	 Link 11: FEC Errors - 14: 0
	 Link 11: FEC Errors - 15: 0

	 Link 12: Tx packets: 128
	 Link 12: Tx bytes: 36864
	 Link 12: Rx packets: 128
	 Link 12: Rx bytes: 36864
	 Link 12: Malformed packet Errors: 0
	 Link 12: Buffer overrun Errors: 0
	 Link 12: Rx Errors: 0
	 Link 12: Rx remote Errors: 0
	 Link 12: Rx General Errors: 0
	 Link 12: Local link integrity Errors: 0
	 Link 12: Tx discards: 0
	 Link 12: Link recovery successful events: 0
	 Link 12: Link recovery failed events: 0
	 Link 12: Total link recovery events: 0
	 Link 12: Effective Errors: 0
	 Link 12: Effective BER: 15e-255
	 Link 12: Symbol Errors: 0
	 Link 12: Symbol BER: 15e-255
	 Link 12: FEC Errors - 0: 2109654598
	 Link 12: FEC Errors - 1: 8
	 Link 12: FEC Errors - 2: 0
	 Link 12: FEC Errors - 3: 0
	 Link 12: FEC Errors - 4: 0
	 Link 12: FEC Errors - 5: 0
	 Link 12: FEC Errors - 6: 0
	 Link 12: FEC Errors - 7: 0
	 Link 12: FEC Errors - 8: 0
	 Link 12: FEC Errors - 9: 0
	 Link 12: FEC Errors - 10: 0
	 Link 12: FEC Errors - 11: 0
	 Link 12: FEC Errors - 12: 0
	 Link 12: FEC Errors - 13: 0
	 Link 12: FEC Errors - 14: 0
	 Link 12: FEC Errors - 15: 0

	 Link 13: Tx packets: 128
	 Link 13: Tx bytes: 36864
	 Link 13: Rx packets: 128
	 Link 13: Rx bytes: 36864
	 Link 13: Malformed packet Errors: 0
	 Link 13: Buffer overrun Errors: 0
	 Link 13: Rx Errors: 0
	 Link 13: Rx remote Errors: 0
	 Link 13: Rx General Errors: 0
	 Link 13: Local link integrity Errors: 0
	 Link 13: Tx discards: 0
	 Link 13: Link recovery successful events: 0
	 Link 13: Link recovery failed events: 0
	 Link 13: Total link recovery events: 0
	 Link 13: Effective Errors: 0
	 Link 13: Effective BER: 15e-255
	 Link 13: Symbol Errors: 0
	 Link 13: Symbol BER: 15e-255
	 Link 13: FEC Errors - 0: 2118527564
	 Link 13: FEC Errors - 1: 14
	 Link 13: FEC Errors - 2: 0
	 Link 13: FEC Errors - 3: 0
	 Link 13: FEC Errors - 4: 0
	 Link 13: FEC Errors - 5: 0
	 Link 13: FEC Errors - 6: 0
	 Link 13: FEC Errors - 7: 0
	 Link 13: FEC Errors - 8: 0
	 Link 13: FEC Errors - 9: 0
	 Link 13: FEC Errors - 10: 0
	 Link 13: FEC Errors - 11: 0
	 Link 13: FEC Errors - 12: 0
	 Link 13: FEC Errors - 13: 0
	 Link 13: FEC Errors - 14: 0
	 Link 13: FEC Errors - 15: 0

	 Link 14: Tx packets: 120
	 Link 14: Tx bytes: 34560
	 Link 14: Rx packets: 120
	 Link 14: Rx bytes: 34560
	 Link 14: Malformed packet Errors: 0
	 Link 14: Buffer overrun Errors: 0
	 Link 14: Rx Errors: 0
	 Link 14: Rx remote Errors: 0
	 Link 14: Rx General Errors: 0
	 Link 14: Local link integrity Errors: 0
	 Link 14: Tx discards: 0
	 Link 14: Link recovery successful events: 0
	 Link 14: Link recovery failed events: 0
	 Link 14: Total link recovery events: 0
	 Link 14: Effective Errors: 0
	 Link 14: Effective BER: 15e-255
	 Link 14: Symbol Errors: 0
	 Link 14: Symbol BER: 15e-255
	 Link 14: FEC Errors - 0: 2099577836
	 Link 14: FEC Errors - 1: 0
	 Link 14: FEC Errors - 2: 0
	 Link 14: FEC Errors - 3: 0
	 Link 14: FEC Errors - 4: 0
	 Link 14: FEC Errors - 5: 0
	 Link 14: FEC Errors - 6: 0
	 Link 14: FEC Errors - 7: 0
	 Link 14: FEC Errors - 8: 0
	 Link 14: FEC Errors - 9: 0
	 Link 14: FEC Errors - 10: 0
	 Link 14: FEC Errors - 11: 0
	 Link 14: FEC Errors - 12: 0
	 Link 14: FEC Errors - 13: 0
	 Link 14: FEC Errors - 14: 0
	 Link 14: FEC Errors - 15: 0

	 Link 15: Tx packets: 128
	 Link 15: Tx bytes: 36864
	 Link 15: Rx packets: 128
	 Link 15: Rx bytes: 36864
	 Link 15: Malformed packet Errors: 0
	 Link 15: Buffer overrun Errors: 0
	 Link 15: Rx Errors: 0
	 Link 15: Rx remote Errors: 0
	 Link 15: Rx General Errors: 0
	 Link 15: Local link integrity Errors: 0
	 Link 15: Tx discards: 0
	 Link 15: Link recovery successful events: 0
	 Link 15: Link recovery failed events: 0
	 Link 15: Total link recovery events: 0
	 Link 15: Effective Errors: 0
	 Link 15: Effective BER: 15e-255
	 Link 15: Symbol Errors: 0
	 Link 15: Symbol BER: 15e-255
	 Link 15: FEC Errors - 0: 2111742548
	 Link 15: FEC Errors - 1: 0
	 Link 15: FEC Errors - 2: 0
	 Link 15: FEC Errors - 3: 0
	 Link 15: FEC Errors - 4: 0
	 Link 15: FEC Errors - 5: 0
	 Link 15: FEC Errors - 6: 0
	 Link 15: FEC Errors - 7: 0
	 Link 15: FEC Errors - 8: 0
	 Link 15: FEC Errors - 9: 0
	 Link 15: FEC Errors - 10: 0
	 Link 15: FEC Errors - 11: 0
	 Link 15: FEC Errors - 12: 0
	 Link 15: FEC Errors - 13: 0
	 Link 15: FEC Errors - 14: 0
	 Link 15: FEC Errors - 15: 0

	 Link 16: Tx packets: 120
	 Link 16: Tx bytes: 34560
	 Link 16: Rx packets: 120
	 Link 16: Rx bytes: 34560
	 Link 16: Malformed packet Errors: 0
	 Link 16: Buffer overrun Errors: 0
	 Link 16: Rx Errors: 0
	 Link 16: Rx remote Errors: 0
	 Link 16: Rx General Errors: 0
	 Link 16: Local link integrity Errors: 0
	 Link 16: Tx discards: 0
	 Link 16: Link recovery successful events: 0
	 Link 16: Link recovery failed events: 0
	 Link 16: Total link recovery events: 0
	 Link 16: Effective Errors: 0
	 Link 16: Effective BER: 15e-255
	 Link 16: Symbol Errors: 0
	 Link 16: Symbol BER: 15e-255
	 Link 16: FEC Errors - 0: 2103989566
	 Link 16: FEC Errors - 1: 0
	 Link 16: FEC Errors - 2: 0
	 Link 16: FEC Errors - 3: 0
	 Link 16: FEC Errors - 4: 0
	 Link 16: FEC Errors - 5: 0
	 Link 16: FEC Errors - 6: 0
	 Link 16: FEC Errors - 7: 0
	 Link 16: FEC Errors - 8: 0
	 Link 16: FEC Errors - 9: 0
	 Link 16: FEC Errors - 10: 0
	 Link 16: FEC Errors - 11: 0
	 Link 16: FEC Errors - 12: 0
	 Link 16: FEC Errors - 13: 0
	 Link 16: FEC Errors - 14: 0
	 Link 16: FEC Errors - 15: 0

	 Link 17: Tx packets: 128
	 Link 17: Tx bytes: 36864
	 Link 17: Rx packets: 128
	 Link 17: Rx bytes: 36864
	 Link 17: Malformed packet Errors: 0
	 Link 17: Buffer overrun Errors: 0
	 Link 17: Rx Errors: 0
	 Link 17: Rx remote Errors: 0
	 Link 17: Rx General Errors: 0
	 Link 17: Local link integrity Errors: 0
	 Link 17: Tx discards: 0
	 Link 17: Link recovery successful events: 0
	 Link 17: Link recovery failed events: 0
	 Link 17: Total link recovery events: 0
	 Link 17: Effective Errors: 0
	 Link 17: Effective BER: 15e-255
	 Link 17: Symbol Errors: 0
	 Link 17: Symbol BER: 15e-255
	 Link 17: FEC Errors - 0: 2115081138
	 Link 17: FEC Errors - 1: 0
	 Link 17: FEC Errors - 2: 0
	 Link 17: FEC Errors - 3: 0
	 Link 17: FEC Errors - 4: 0
	 Link 17: FEC Errors - 5: 0
	 Link 17: FEC Errors - 6: 0
	 Link 17: FEC Errors - 7: 0
	 Link 17: FEC Errors - 8: 0
	 Link 17: FEC Errors - 9: 0
	 Link 17: FEC Errors - 10: 0
	 Link 17: FEC Errors - 11: 0
	 Link 17: FEC Errors - 12: 0
	 Link 17: FEC Errors - 13: 0
	 Link 17: FEC Errors - 14: 0
	 Link 17: FEC Errors - 15: 0



--- GPU Clocks and Power ---

[CMD] Clock speeds: nvidia-smi -q -d CLOCK

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:18 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    Clocks
        Graphics                          : 772 MHz
        SM                                : 772 MHz
        Memory                            : 3996 MHz
        Video                             : 802 MHz
    Applications Clocks
        Graphics                          : 1965 MHz
        Memory                            : 3996 MHz
    Default Applications Clocks
        Graphics                          : 1965 MHz
        Memory                            : 3996 MHz
    Deferred Clocks
        Memory                            : N/A
    Max Clocks
        Graphics                          : 1965 MHz
        SM                                : 1965 MHz
        Memory                            : 3996 MHz
        Video                             : 1965 MHz
    Max Customer Boost Clocks
        Graphics                          : 1965 MHz
    SM Clock Samples
        Duration                          : N/A
        Number of Samples                 : N/A
        Max                               : N/A
        Min                               : N/A
        Avg                               : N/A
    Memory Clock Samples
        Duration                          : N/A
        Number of Samples                 : N/A
        Max                               : N/A
        Min                               : N/A
        Avg                               : N/A
    Clock Policy
        Auto Boost                        : N/A
        Auto Boost Default                : N/A


[CMD] Power readings: nvidia-smi -q -d POWER

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:19 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    GPU Power Readings
        Average Power Draw                : 148.42 W
        Instantaneous Power Draw          : 151.93 W
        Current Power Limit               : 1000.00 W
        Requested Power Limit             : 1000.00 W
        Default Power Limit               : 1000.00 W
        Min Power Limit                   : 200.00 W
        Max Power Limit                   : 1000.00 W
    Power Samples
        Duration                          : 2.43 sec
        Number of Samples                 : 119
        Max                               : 187.56 W
        Min                               : 144.60 W
        Avg                               : 146.68 W
    GPU Memory Power Readings 
        Average Power Draw                : 17.97 W
        Instantaneous Power Draw          : N/A
    Module Power Readings
        Average Power Draw                : N/A
        Instantaneous Power Draw          : N/A
        Current Power Limit               : N/A
        Requested Power Limit             : N/A
        Default Power Limit               : N/A
        Min Power Limit                   : N/A
        Max Power Limit                   : N/A


[CMD] Performance state: nvidia-smi -q -d PERFORMANCE

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:19 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    Performance State                     : P0
    Clocks Event Reasons
        Idle                              : Active
        Applications Clocks Setting       : Not Active
        SW Power Cap                      : Not Active
        HW Slowdown                       : Not Active
            HW Thermal Slowdown           : Not Active
            HW Power Brake Slowdown       : Not Active
        Sync Boost                        : Not Active
        SW Thermal Slowdown               : Not Active
        Display Clock Setting             : Not Active
    Sparse Operation Mode                 : N/A



--- GPU Memory (B200: 180GB HBM3e expected) ---

[CMD] Memory info: nvidia-smi -q -d MEMORY

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:19 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    FB Memory Usage
        Total                             : 183359 MiB
        Reserved                          : 718 MiB
        Used                              : 0 MiB
        Free                              : 182642 MiB
    BAR1 Memory Usage
        Total                             : 262144 MiB
        Used                              : 1 MiB
        Free                              : 262143 MiB
    Conf Compute Protected Memory Usage
        Total                             : 0 MiB
        Used                              : 0 MiB
        Free                              : 0 MiB


[CMD] ECC status: nvidia-smi -q -d ECC

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:19 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    ECC Mode
        Current                           : Enabled
        Pending                           : Enabled
    ECC Errors
        Volatile
            SRAM Correctable              : 0
            SRAM Uncorrectable Parity     : 0
            SRAM Uncorrectable SEC-DED    : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
        Aggregate
            SRAM Correctable              : 0
            SRAM Uncorrectable Parity     : 0
            SRAM Uncorrectable SEC-DED    : 0
            DRAM Correctable              : 0
            DRAM Uncorrectable            : 0
            SRAM Threshold Exceeded       : No
        Aggregate Uncorrectable SRAM Sources
            SRAM L2                       : 0
            SRAM SM                       : 0
            SRAM Microcontroller          : 0
            SRAM PCIE                     : 0
            SRAM Other                    : 0


[CMD] Retired pages: nvidia-smi -q -d PAGE_RETIREMENT

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:19 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    Retired Pages
        Single Bit ECC                    : N/A
        Double Bit ECC                    : N/A
        Pending Page Blacklist            : N/A



--- MIG Configuration ---

[CMD] MIG mode: nvidia-smi -q -d MIG
Failed to parse --display/-d flags
[WARN] Command returned non-zero exit code

[CMD] MIG devices: nvidia-smi mig -lgi
No MIG-enabled devices found.


--- Compute Mode and Processes ---

[CMD] Compute mode: nvidia-smi -q -d COMPUTE

==============NVSMI LOG==============

Timestamp                                 : Thu Dec 18 20:54:19 2025
Driver Version                            : 570.195.03
CUDA Version                              : 12.8

Attached GPUs                             : 1
GPU 00000000:07:00.0
    Compute Mode                          : Default


[CMD] Running processes: nvidia-smi pmon -c 1
# gpu         pid   type     sm    mem    enc    dec    jpg    ofa    command 
# Idx           #    C/G      %      %      %      %      %      %    name 
    0          -     -      -      -      -      -      -      -    -              


--- PCIe Configuration (B200: Gen5 x16 expected) ---

[CMD] GPU PCIe info: nvidia-smi -q -d PCIE
Failed to parse --display/-d flags
[WARN] Command returned non-zero exit code

[CMD] PCIe link gen/width: nvidia-smi --query-gpu=pcie.link.gen.current,pcie.link.width.current --format=csv
pcie.link.gen.current, pcie.link.width.current
5, 16


--- All GPU Properties ---

[CMD] GPU properties CSV: nvidia-smi --query-gpu=name,driver_version,pstate,memory.total,memory.used,memory.free,compute_mode,gpu_bus_id,gpu_uuid --format=csv
name, driver_version, pstate, memory.total [MiB], memory.used [MiB], memory.free [MiB], compute_mode, pci.bus_id, uuid
NVIDIA B200, 570.195.03, P0, 183359 MiB, 0 MiB, 182642 MiB, Default, 00000000:07:00.0, GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3


--- DCGM (Data Center GPU Manager) ---

[SKIP] DCGM not installed (optional for monitoring)

===============================================================================
  PHASE 4: INFINIBAND / RDMA NETWORKING
  2025-12-18 20:54:19
===============================================================================


--- OFED Version (Lambda includes MLNX_OFED) ---

[INFO] Lambda Labs includes OFED for InfiniBand/RDMA support
[INFO] MLNX_OFED transitioning to DOCA-OFED (Jan 2025+)

[CMD] OFED version: ofed_info -s
OFED-internal-24.10-3.2.5:

[CMD] OFED full info: ofed_info
OFED-internal-24.10-3.2.5:

clusterkit:
/sw/release/mlnx_ofed/IBHPC/OFED-internal-24.10-1.1.4/SRPMS/clusterkit-1.14.462-1.2410068.src.rpm

dpcp:
/sw/release/mlnx_ofed/IBHPC/OFED-internal-24.10-1.1.4/SRPMS/dpcp-1.1.50-1.2410068.src.rpm

fwctl:
https://git-nbu.nvidia.com/r/a/mlnx_ofed/mlnx-ofa_kernel-4.0.git mlnx_ofed_24_10
commit 8ad7fe3a2b478f864b9d2baace8eeef6f1b39248

hcoll:
/sw/release/mlnx_ofed/IBHPC/OFED-internal-24.10-1.1.4/SRPMS/hcoll-4.8.3230-1.2410068.src.rpm

ibarr:
/sw/release/mlnx_ofed/IBHPC/OFED-internal-24.10-1.1.4/SRPMS/ibarr-0.1.3-1.2410068.src.rpm

ibdump:
/sw/release/mlnx_ofed/IBHPC/OFED-internal-24.10-1.1.4/SRPMS/ibdump-6.0.0-1.2410068.src.rpm

ibsim:
/sw/release/mlnx_ofed/IBHPC/OFED-internal-24.10-1.1.4/SRPMS/ibsim-0.12-1.2410068.src.rpm

ibutils2:
ibutils2/ibutils2-2.1.1-0.21905.MLNX20250604.g53bdce92c.tar.gz

iser:
https://git-nbu.nvidia.com/r/a/mlnx_ofed/mlnx-ofa_kernel-4.0.git mlnx_ofed_24_10
[CMD] DOCA version: doca_version
[SKIP] Command not found: doca_version


--- InfiniBand Device Status ---

[CMD] IB status: ibstat
CA 'mlx5_0'
	CA type: MT4126
	Number of ports: 1
	Firmware version: 28.40.1202
	Hardware version: 0
	Node GUID: 0x020017fffe055030
	System image GUID: 0xc470bd0300bae230
	Port 1:
		State: Active
		Physical state: LinkUp
		Rate: 200
		Base lid: 0
		LMC: 0
		SM lid: 0
		Capability mask: 0x00010000
		Port GUID: 0x000017fffe055030
		Link layer: Ethernet

[CMD] IB device info: ibv_devinfo
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
hca_id:	mlx5_0
	transport:			InfiniBand (0)
	fw_ver:				28.40.1202
	node_guid:			0200:17ff:fe05:5030
	sys_image_guid:			c470:bd03:00ba:e230
	vendor_id:			0x02c9
	vendor_part_id:			4126
	hw_ver:				0x0
	board_id:			ORC0000000014
	phys_port_cnt:			1
		port:	1
			state:			PORT_ACTIVE (4)
			max_mtu:		4096 (5)
			active_mtu:		1024 (3)
			sm_lid:			0
			port_lid:		0
			port_lmc:		0x00
			link_layer:		Ethernet


[CMD] IB devices list: ibv_devices
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
    device          	   node GUID
    ------          	----------------
    mlx5_0          	020017fffe055030

[CMD] IB link info: iblinkinfo
ibwarn: [2098] mad_rpc_open_port: can't open UMAD port ((null):0)
Failed to open (null) port 0
[WARN] Command returned non-zero exit code


--- RDMA Configuration ---

[CMD] RDMA devices: rdma link show
link mlx5_0/1 state ACTIVE physical_state LINK_UP netdev eno1 

[CMD] RDMA system: rdma system show
netns shared copy-on-fork on

[DIR] /sys/class/infiniband:
total 0
drwxr-xr-x  2 root root 0 Dec 18 20:54 .
drwxr-xr-x 71 root root 0 Dec 18 20:47 ..
lrwxrwxrwx  1 root root 0 Dec 18 20:47 mlx5_0 -> ../../devices/pci0000:00/0000:00:02.5/0000:06:00.0/infiniband/mlx5_0


--- GPUDirect RDMA (nvidia-peermem) ---

[INFO] nvidia-peermem enables direct GPU-to-NIC transfers for InfiniBand
nvidia_peermem         16384  0
nvidia              11653120  8 nvidia_uvm,nvidia_peermem,nvidia_modeset
ib_uverbs             200704  3 nvidia_peermem,rdma_ucm,mlx5_ib
[CMD] Peer memory status: cat /sys/kernel/mm/memory_peers/nv_mem/version
cat: /sys/kernel/mm/memory_peers/nv_mem/version: No such file or directory
[WARN] Command returned non-zero exit code


--- Network Interfaces ---

[CMD] IP addresses: ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host noprefixroute 
       valid_lft forever preferred_lft forever
2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 02:00:17:05:50:30 brd ff:ff:ff:ff:ff:ff
    altname enp6s0
    inet 10.19.109.122/24 brd 10.19.109.255 scope global eno1
       valid_lft forever preferred_lft forever
    inet6 fe80::17ff:fe05:5030/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 4e:fd:da:11:a1:8b brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever

[CMD] Network interfaces: ip link show
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
    link/ether 02:00:17:05:50:30 brd ff:ff:ff:ff:ff:ff
    altname enp6s0
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default 
    link/ether 4e:fd:da:11:a1:8b brd ff:ff:ff:ff:ff:ff

[CMD] Routing table: ip route
default via 10.19.109.1 dev eno1 proto static 
10.19.109.0/24 dev eno1 proto kernel scope link src 10.19.109.122 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 

1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default 
	Speed: 200000Mb/s
	Duplex: Full
	Link detected: yes

===============================================================================
  PHASE 5: SYSTEM HARDWARE
  2025-12-18 20:54:19
===============================================================================


--- CPU Information ---

[CMD] lscpu: lscpu
Architecture:                         x86_64
CPU op-mode(s):                       32-bit, 64-bit
Address sizes:                        46 bits physical, 57 bits virtual
Byte Order:                           Little Endian
CPU(s):                               26
On-line CPU(s) list:                  0-25
Vendor ID:                            GenuineIntel
Model name:                           INTEL(R) XEON(R) PLATINUM 8592+
CPU family:                           6
Model:                                207
Thread(s) per core:                   2
Core(s) per socket:                   13
Socket(s):                            1
Stepping:                             2
BogoMIPS:                             3800.00
Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq dtes64 vmx ssse3 fma cx16 pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves avx_vnni avx512_bf16 wbnoinvd arat vnmi avx512vbmi umip pku ospke waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq la57 rdpid bus_lock_detect cldemote movdiri movdir64b fsrm md_clear serialize tsxldtrk amx_bf16 avx512_fp16 amx_tile amx_int8 flush_l1d arch_capabilities
Virtualization:                       VT-x
Hypervisor vendor:                    KVM
Virtualization type:                  full
L1d cache:                            832 KiB (26 instances)
L1i cache:                            832 KiB (26 instances)
L2 cache:                             52 MiB (13 instances)
L3 cache:                             16 MiB (1 instance)
NUMA node(s):                         1
NUMA node0 CPU(s):                    0-25
Vulnerability Gather data sampling:   Not affected
Vulnerability Itlb multihit:          Not affected
Vulnerability L1tf:                   Not affected
Vulnerability Mds:                    Not affected
Vulnerability Meltdown:               Not affected
Vulnerability Mmio stale data:        Not affected
Vulnerability Reg file data sampling: Not affected
Vulnerability Retbleed:               Not affected
Vulnerability Spec rstack overflow:   Not affected
Vulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl
Vulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; RSB filling; PBRSB-eIBRS SW sequence; BHI SW loop, KVM SW loop
Vulnerability Srbds:                  Not affected
Vulnerability Tsx async abort:        Mitigation; TSX disabled

model name	: INTEL(R) XEON(R) PLATINUM 8592+

--- NUMA Topology (GPU-CPU affinity) ---

[CMD] numactl hardware: numactl --hardware
available: 1 nodes (0)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
node 0 size: 362564 MB
node 0 free: 360696 MB
node distances:
node   0 
  0:  10 

[CMD] numactl show: numactl --show
policy: default
preferred node: current
physcpubind: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 
cpubind: 0 
nodebind: 0 
membind: 0 
preferred: 

[CMD] NUMA info from lscpu: lscpu
NUMA node(s):                         1
NUMA node0 CPU(s):                    0-25

--- Memory Hardware ---

[CMD] dmidecode memory: sudo dmidecode -t memory
# dmidecode 3.5
Getting SMBIOS data from sysfs.
SMBIOS 3.0.0 present.

Handle 0x1000, DMI type 16, 23 bytes
Physical Memory Array
	Location: Other
	Use: System Memory
	Error Correction Type: Multi-bit ECC
	Maximum Capacity: 360 GB
	Error Information Handle: Not Provided
	Number Of Devices: 23

Handle 0x1100, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x1000
	Error Information Handle: Not Provided
	Total Width: Unknown
	Data Width: Unknown
	Size: 16 GB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 0
	Bank Locator: Not Specified
	Type: RAM
	Type Detail: Other
	Speed: Unknown
	Manufacturer: QEMU
	Serial Number: Not Specified
	Asset Tag: Not Specified
	Part Number: Not Specified
	Rank: Unknown
	Configured Memory Speed: Unknown
	Minimum Voltage: Unknown
	Maximum Voltage: Unknown
	Configured Voltage: Unknown

Handle 0x1101, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x1000
	Error Information Handle: Not Provided
	Total Width: Unknown
	Data Width: Unknown
	Size: 16 GB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 1
	Bank Locator: Not Specified
	Type: RAM
	Type Detail: Other
	Speed: Unknown
	Manufacturer: QEMU
	Serial Number: Not Specified
	Asset Tag: Not Specified
	Part Number: Not Specified
	Rank: Unknown
	Configured Memory Speed: Unknown
	Minimum Voltage: Unknown
	Maximum Voltage: Unknown
	Configured Voltage: Unknown

Handle 0x1102, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x1000
	Error Information Handle: Not Provided
	Total Width: Unknown
	Data Width: Unknown
	Size: 16 GB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 2
	Bank Locator: Not Specified
	Type: RAM
	Type Detail: Other
	Speed: Unknown
	Manufacturer: QEMU
	Serial Number: Not Specified
	Asset Tag: Not Specified
	Part Number: Not Specified
	Rank: Unknown
	Configured Memory Speed: Unknown
	Minimum Voltage: Unknown
	Maximum Voltage: Unknown
	Configured Voltage: Unknown

Handle 0x1103, DMI type 17, 40 bytes
Memory Device
	Array Handle: 0x1000
	Error Information Handle: Not Provided
	Total Width: Unknown
	Data Width: Unknown
	Size: 16 GB
	Form Factor: DIMM
	Set: None
	Locator: DIMM 3
	Bank Locator: Not Specified
	Type: RAM
	Type Detail: Other
	Speed: Unknown
[SKIP] Need sudo for dmidecode
[FILE] /proc/meminfo:
MemTotal:       371265576 kB
MemFree:        369349852 kB
MemAvailable:   367700300 kB
Buffers:          219688 kB
Cached:           847292 kB
SwapCached:            0 kB
Active:           284084 kB
Inactive:         829384 kB
Active(anon):      60316 kB
Inactive(anon):        0 kB
Active(file):     223768 kB
Inactive(file):   829384 kB
Unevictable:       31284 kB
Mlocked:           27284 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Zswap:                 0 kB
Zswapped:              0 kB
Dirty:                88 kB
Writeback:             0 kB
AnonPages:         77736 kB
Mapped:           120116 kB
Shmem:              4992 kB
KReclaimable:      45404 kB
Slab:             212712 kB
SReclaimable:      45404 kB
SUnreclaim:       167308 kB
KernelStack:        7104 kB
PageTables:         3488 kB
SecPageTables:         0 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    185632788 kB
Committed_AS:     482168 kB
VmallocTotal:   13743895347199 kB
VmallocUsed:       48352 kB
VmallocChunk:          0 kB
Percpu:            13552 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
Unaccepted:            0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB
DirectMap4k:      331428 kB
DirectMap2M:     4907008 kB
DirectMap1G:    374341632 kB


--- PCIe Devices ---

[CMD] All PCIe devices: lspci
00:00.0 Host bridge: Intel Corporation 82G33/G31/P35/P31 Express DRAM Controller
00:01.0 VGA compatible controller: Red Hat, Inc. Virtio 1.0 GPU (rev 01)
00:02.0 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.1 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.2 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.3 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.4 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.5 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.6 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:02.7 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:03.0 PCI bridge: Red Hat, Inc. QEMU PCIe Root port
00:1f.0 ISA bridge: Intel Corporation 82801IB (ICH9) LPC Interface Controller (rev 02)
00:1f.2 SATA controller: Intel Corporation 82801IR/IO/IH (ICH9R/DO/DH) 6 port SATA Controller [AHCI mode] (rev 02)
00:1f.3 SMBus: Intel Corporation 82801I (ICH9 Family) SMBus Controller (rev 02)
01:00.0 Mass storage controller: Red Hat, Inc. Virtio file system (rev 01)
02:00.0 Communication controller: Red Hat, Inc. Virtio 1.0 console (rev 01)
03:00.0 USB controller: Red Hat, Inc. QEMU XHCI Host Controller (rev 01)
04:00.0 SCSI storage controller: Red Hat, Inc. Virtio 1.0 block device (rev 01)
05:00.0 SCSI storage controller: Red Hat, Inc. Virtio 1.0 block device (rev 01)
06:00.0 Ethernet controller: Mellanox Technologies ConnectX Family mlx5Gen Virtual Function
07:00.0 3D controller: NVIDIA Corporation Device 2901 (rev a1)
08:00.0 Communication controller: Red Hat, Inc. Virtio 1.0 socket (rev 01)

[CMD] NVIDIA PCIe detailed: lspci -d 10de: -vvv
07:00.0 3D controller: NVIDIA Corporation Device 2901 (rev a1)
	Subsystem: NVIDIA Corporation Device 1999
	Physical Slot: 0-7
	Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx+
	Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx-
	Latency: 0
	Interrupt: pin A routed to IRQ 22
	Region 0: Memory at 384000000000 (64-bit, prefetchable) [size=64M]
	Region 2: Memory at 380000000000 (64-bit, prefetchable) [size=256G]
	Region 4: Memory at 384004000000 (64-bit, prefetchable) [size=32M]
	Capabilities: <access denied>
	Kernel driver in use: nvidia
	Kernel modules: nvidiafb, nvidia_drm, nvidia


[CMD] PCIe tree: lspci -tv
-[0000:00]-+-00.0  Intel Corporation 82G33/G31/P35/P31 Express DRAM Controller
           +-01.0  Red Hat, Inc. Virtio 1.0 GPU
           +-02.0-[01]----00.0  Red Hat, Inc. Virtio file system
           +-02.1-[02]----00.0  Red Hat, Inc. Virtio 1.0 console
           +-02.2-[03]----00.0  Red Hat, Inc. QEMU XHCI Host Controller
           +-02.3-[04]----00.0  Red Hat, Inc. Virtio 1.0 block device
           +-02.4-[05]----00.0  Red Hat, Inc. Virtio 1.0 block device
           +-02.5-[06]----00.0  Mellanox Technologies ConnectX Family mlx5Gen Virtual Function
           +-02.6-[07]----00.0  NVIDIA Corporation Device 2901
           +-02.7-[08]----00.0  Red Hat, Inc. Virtio 1.0 socket
           +-03.0-[09]--
           +-1f.0  Intel Corporation 82801IB (ICH9) LPC Interface Controller
           +-1f.2  Intel Corporation 82801IR/IO/IH (ICH9R/DO/DH) 6 port SATA Controller [AHCI mode]
           \-1f.3  Intel Corporation 82801I (ICH9 Family) SMBus Controller


--- Storage ---

[CMD] Block devices: lsblk -o NAME,SIZE,TYPE,FSTYPE,MOUNTPOINT,MODEL
NAME     SIZE TYPE FSTYPE  MOUNTPOINT MODEL
vda      2.8T disk                    
‚îú‚îÄvda1   2.7T part ext4    /          
‚îú‚îÄvda14    4M part                    
‚îú‚îÄvda15  106M part vfat    /boot/efi  
‚îî‚îÄvda16  913M part ext4    /boot      
vdb      386K disk iso9660            

[CMD] Disk usage: df -h
Filesystem                            Size  Used Avail Use% Mounted on
tmpfs                                  36G  984K   36G   1% /run
efivarfs                              256K   20K  232K   8% /sys/firmware/efi/efivars
/dev/vda1                             2.7T   15G  2.7T   1% /
tmpfs                                 178G     0  178G   0% /dev/shm
tmpfs                                 5.0M     0  5.0M   0% /run/lock
/dev/vda16                            881M  106M  714M  13% /boot
/dev/vda15                            105M  6.2M   99M   6% /boot/efi
b215a5c3-f53d-48e1-8fb1-b7ee1e9393c9  8.0E     0  8.0E   0% /lambda/nfs/Test
tmpfs                                  36G  8.0K   36G   1% /run/user/1000

[CMD] NVMe devices: nvme list
[SKIP] Command not found: nvme


--- IOMMU Configuration ---

2
[CMD] Kernel cmdline: cat /proc/cmdline
BOOT_IMAGE=/vmlinuz-6.11.0-1016-nvidia root=UUID=52645fa4-47a3-4335-8817-2637487e1980 ro console=tty1 console=ttyS0


--- Huge Pages (GPU Memory Performance) ---

[INFO] Huge pages can improve GPU memory mapping performance
[CMD] Huge pages config: grep -i huge /proc/meminfo
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
FileHugePages:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB

[CMD] Transparent huge pages: cat /sys/kernel/mm/transparent_hugepage/enabled
always [madvise] never

[CMD] THP defrag: cat /sys/kernel/mm/transparent_hugepage/defrag
always defer defer+madvise [madvise] never


--- Cgroups Configuration ---

[INFO] cgroups v2 is preferred for modern container runtimes
[CMD] Cgroups version: stat -fc %T /sys/fs/cgroup
cgroup2fs

cgroup2 on /sys/fs/cgroup type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate,memory_recursiveprot)
[FILE] /sys/fs/cgroup/cgroup.controllers:
cpuset cpu io memory hugetlb pids rdma misc


===============================================================================
  PHASE 6: CUDA AND NVIDIA SOFTWARE STACK
  2025-12-18 20:54:19
===============================================================================


--- CUDA Installations ---

[CMD] CUDA version (nvcc): nvcc --version
[SKIP] Command not found: nvcc

[SKIP] File/dir not found: /usr/local/cuda/version.txt

[SKIP] File/dir not found: /usr/local/cuda/version.json

lrwxrwxrwx  1 root root   22 Oct 17 20:32 cuda -> /etc/alternatives/cuda
lrwxrwxrwx  1 root root   25 Oct 17 20:32 cuda-12 -> /etc/alternatives/cuda-12
drwxr-xr-x 12 root root 4096 Oct 17 20:32 cuda-12.8

--- NVIDIA Libraries ---

	libpcsamplingutil.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libpcsamplingutil.so
	libnvrtc.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc.so.12
	libnvrtc.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc.so
	libnvrtc.alt.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc.alt.so.12
	libnvrtc.alt.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc.alt.so
	libnvrtc-builtins.so.12.8 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc-builtins.so.12.8
	libnvrtc-builtins.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc-builtins.so
	libnvrtc-builtins.alt.so.12.8 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc-builtins.alt.so.12.8
	libnvrtc-builtins.alt.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvrtc-builtins.alt.so
	libnvperf_target.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvperf_target.so
	libnvperf_host.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvperf_host.so
	libnvjpeg.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvjpeg.so.12
	libnvjpeg.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvjpeg.so
	libnvidia-sandboxutils.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-sandboxutils.so.1
	libnvidia-ptxjitcompiler.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1
	libnvidia-pkcs11-openssl3.so.570.195.03 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-pkcs11-openssl3.so.570.195.03
	libnvidia-opticalflow.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-opticalflow.so.1
	libnvidia-opencl.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-opencl.so.1
	libnvidia-nvvm.so.4 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-nvvm.so.4
	libnvidia-nscq.so.2 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-nscq.so.2
	libnvidia-nscq.so (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-nscq.so
	libnvidia-ml.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-ml.so.1
	libnvidia-container.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-container.so.1
	libnvidia-container-go.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-container-go.so.1
	libnvidia-cfg.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-cfg.so.1
	libnvidia-allocator.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libnvidia-allocator.so.1
	libnvfatbin.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvfatbin.so.12
	libnvfatbin.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvfatbin.so
	libnvblas.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvblas.so.12
	libnvblas.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libnvblas.so
[CMD] cuDNN version header: grep -E CUDNN_MAJOR|CUDNN_MINOR|CUDNN_PATCHLEVEL /usr/include/cudnn_version.h
grep: /usr/include/cudnn_version.h: No such file or directory
[WARN] Command returned non-zero exit code

[CMD] NCCL version header: grep -E NCCL_MAJOR|NCCL_MINOR|NCCL_PATCH /usr/include/nccl.h
#define NCCL_MAJOR 2
#define NCCL_MINOR 27
#define NCCL_PATCH 7
  NCCL_VERSION(NCCL_MAJOR, NCCL_MINOR, NCCL_PATCH), /* version */       \
  NCCL_VERSION(NCCL_MAJOR, NCCL_MINOR, NCCL_PATCH), /* version */           \


--- NVIDIA Packages ---

[CMD] NVIDIA dpkg packages: dpkg -l
ii  cuda-nvtx-12-8                             12.8.90-1                                     amd64        NVIDIA Tools Extension
ii  cudnn9-cuda-12                             9.14.0.64-1                                   amd64        NVIDIA cuDNN for CUDA 12
ii  cudnn9-cuda-12-9                           9.14.0.64-1                                   amd64        NVIDIA cuDNN for CUDA 12.9
ii  ibarr:amd64                                0.1.3-1.2410068                               amd64        Nvidia address and route userspace resolution services for Infiniband
hi  libnccl-dev                                2.27.7-1+cuda12.9                             amd64        NVIDIA Collective Communication Library (NCCL) Development Files
hi  libnccl2                                   2.27.7-1+cuda12.9                             amd64        NVIDIA Collective Communication Library (NCCL) Runtime
ii  libnvidia-cfg1-570:amd64                   570.195.03-0ubuntu1                           amd64        NVIDIA binary OpenGL/GLX configuration library
ii  libnvidia-compute-570:amd64                570.195.03-0ubuntu1                           amd64        NVIDIA libcompute package
ii  libnvidia-container-tools                  1.17.8-1                                      amd64        NVIDIA container runtime library (command-line tools)
ii  libnvidia-container1:amd64                 1.17.8-1                                      amd64        NVIDIA container runtime library
ii  libnvidia-decode-570:amd64                 570.195.03-0ubuntu1                           amd64        NVIDIA Video Decoding runtime libraries
ii  libnvidia-extra-570:amd64                  570.195.03-0ubuntu1                           amd64        Extra libraries for the NVIDIA driver
ii  libnvidia-nscq-570                         570.195.03-1                                  amd64        NVSwitch Configuration and Query library
ii  libnvsdm-570                               570.195.03-1                                  amd64        NVIDIA NVSDM provides library to retrieve telemetry from QM switches
ii  linux-headers-6.11.0-1016-nvidia           6.11.0-1016.16                                amd64        Linux kernel headers for version 6.11.0 on 64 bit x86 SMP
ii  linux-headers-nvidia-hwe-24.04             6.11.0-1016.16                                amd64        NVIDIA Linux kernel headers
ii  linux-image-6.11.0-1016-nvidia             6.11.0-1016.16                                amd64        Signed kernel image nvidia
ii  linux-image-nvidia-hwe-24.04               6.11.0-1016.16                                amd64        NVIDIA Linux kernel image
ii  linux-modules-6.11.0-1016-nvidia           6.11.0-1016.16                                amd64        Linux kernel extra modules for version 6.11.0 on 64 bit x86 SMP
ii  linux-modules-extra-6.11.0-1016-nvidia     6.11.0-1016.16                                amd64        Linux kernel extra modules for version 6.11.0 on 64 bit x86 SMP
ii  linux-modules-nvidia-fs-6.11.0-1016-nvidia 6.11.0-1016.16                                amd64        Linux kernel nvidia-fs modules for version 6.11.0-1016
ii  linux-nvidia-6.11-headers-6.11.0-1016      6.11.0-1016.16                                all          Header files related to Linux kernel version 6.11.0
ii  linux-nvidia-6.11-tools-6.11.0-1016        6.11.0-1016.16                                amd64        Linux kernel version specific tools for version 6.11.0-1016
ii  linux-nvidia-hwe-24.04                     6.11.0-1016.16                                amd64        Complete NVIDIA Linux kernel and headers
ii  linux-tools-6.11.0-1016-nvidia             6.11.0-1016.16                                amd64        Linux kernel version specific tools for version 6.11.0-1016
ii  linux-tools-nvidia-hwe-24.04               6.11.0-1016.16                                amd64        NVIDIA Linux kernel tools
ii  nvidia-container-toolkit                   1.17.8-1                                      amd64        NVIDIA Container toolkit
ii  nvidia-container-toolkit-base              1.17.8-1                                      amd64        NVIDIA Container Toolkit Base
ii  nvidia-dkms-570-open                       570.195.03-0ubuntu1                           amd64        NVIDIA DKMS package (open kernel module)
ii  nvidia-fabricmanager-570                   570.195.03-1                                  amd64        Fabric Manager for NVSwitch based systems.
ii  nvidia-firmware-570                        570.195.03-0ubuntu1                           amd64        Firmware files used by the kernel module
ii  nvidia-headless-570-open                   570.195.03-0ubuntu1                           amd64        NVIDIA headless metapackage (open kernel module)
ii  nvidia-headless-no-dkms-570-open           570.195.03-0ubuntu1                           amd64        NVIDIA headless metapackage - no DKMS (open kernel module)
ii  nvidia-kernel-common-570                   570.195.03-0ubuntu1                           amd64        Shared files used with the kernel module
ii  nvidia-kernel-source-570-open              570.195.03-0ubuntu1                           amd64        NVIDIA kernel source package
ii  nvidia-modprobe                            580.95.05-0ubuntu1                            amd64        Load the NVIDIA kernel driver and create device files
ii  nvidia-persistenced                        580.95.05-0ubuntu1                            amd64        daemon to maintain persistent software state in the NVIDIA driver
[CMD] CUDA dpkg packages: dpkg -l
ii  cuda-cccl-12-8                             12.8.90-1                                     amd64        CUDA CCCL
ii  cuda-command-line-tools-12-8               12.8.1-1                                      amd64        CUDA command-line tools
ii  cuda-compiler-12-8                         12.8.1-1                                      amd64        CUDA compiler
ii  cuda-crt-12-8                              12.8.93-1                                     amd64        CUDA crt
ii  cuda-cudart-12-8                           12.8.90-1                                     amd64        CUDA Runtime native Libraries
ii  cuda-cudart-dev-12-8                       12.8.90-1                                     amd64        CUDA Runtime native dev links, headers
ii  cuda-cuobjdump-12-8                        12.8.90-1                                     amd64        CUDA cuobjdump
ii  cuda-cupti-12-8                            12.8.90-1                                     amd64        CUDA profiling tools runtime libs.
ii  cuda-cupti-dev-12-8                        12.8.90-1                                     amd64        CUDA profiling tools interface.
ii  cuda-cuxxfilt-12-8                         12.8.90-1                                     amd64        CUDA cuxxfilt
ii  cuda-driver-dev-12-8                       12.8.90-1                                     amd64        CUDA Driver native dev stub library
ii  cuda-gdb-12-8                              12.8.90-1                                     amd64        CUDA-GDB
ii  cuda-libraries-12-8                        12.8.1-1                                      amd64        CUDA Libraries 12.8 meta-package
ii  cuda-libraries-dev-12-8                    12.8.1-1                                      amd64        CUDA Libraries 12.8 development meta-package
ii  cuda-nvcc-12-8                             12.8.93-1                                     amd64        CUDA nvcc
ii  cuda-nvdisasm-12-8                         12.8.90-1                                     amd64        CUDA disassembler
ii  cuda-nvml-dev-12-8                         12.8.90-1                                     amd64        NVML native dev links, headers
ii  cuda-nvprof-12-8                           12.8.90-1                                     amd64        CUDA Profiler tools
ii  cuda-nvprune-12-8                          12.8.90-1                                     amd64        CUDA nvprune

--- NVIDIA Container Toolkit ---

[CMD] nvidia-container-cli: nvidia-container-cli info
NVRM version:   570.195.03
CUDA version:   12.8

Device Index:   0
Device Minor:   0
Model:          NVIDIA B200
Brand:          Nvidia
GPU UUID:       GPU-412e7c5b-a499-4bcf-948f-13085dd6b0e3
Bus Location:   00000000:07:00.0
Architecture:   10.0

[FILE] /etc/nvidia-container-runtime/config.toml:
#accept-nvidia-visible-devices-as-volume-mounts = false
#accept-nvidia-visible-devices-envvar-when-unprivileged = true
disable-require = false
supported-driver-capabilities = "compat32,compute,display,graphics,ngx,utility,video"
#swarm-resource = "DOCKER_RESOURCE_GPU"

[nvidia-container-cli]
#debug = "/var/log/nvidia-container-toolkit.log"
environment = []
#ldcache = "/etc/ld.so.cache"
ldconfig = "@/sbin/ldconfig.real"
load-kmods = true
#no-cgroups = false
#path = "/usr/bin/nvidia-container-cli"
#root = "/run/nvidia/driver"
#user = "root:video"

[nvidia-container-runtime]
#debug = "/var/log/nvidia-container-runtime.log"
log-level = "info"
mode = "auto"
runtimes = ["docker-runc", "runc", "crun"]

[nvidia-container-runtime.modes]

[nvidia-container-runtime.modes.cdi]
annotation-prefixes = ["cdi.k8s.io/"]
default-kind = "nvidia.com/gpu"
spec-dirs = ["/etc/cdi", "/var/run/cdi"]

[nvidia-container-runtime.modes.csv]
mount-spec-path = "/etc/nvidia-container-runtime/host-files-for-container.d"

[nvidia-container-runtime.modes.legacy]
cuda-compat-mode = "ldconfig"

[nvidia-container-runtime-hook]
path = "nvidia-container-runtime-hook"
skip-mode-detection = false

[nvidia-ctk]
path = "nvidia-ctk"


--- Environment Variables ---

DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
[CMD] CUDA env vars: env

===============================================================================
  PHASE 7: ML FRAMEWORKS - BLACKWELL COMPATIBILITY
  2025-12-18 20:54:19
===============================================================================


--- Python Environments ---

[CMD] Python version: python3 --version
Python 3.12.3

[CMD] Python path: which python3
/usr/bin/python3

[CMD] Pip version: pip3 --version
pip 24.0 from /usr/lib/python3/dist-packages/pip (python 3.12)

[CMD] Conda info: conda info
[SKIP] Command not found: conda

[CMD] Conda envs: conda env list
[SKIP] Command not found: conda


--- PyTorch Blackwell/SM_100 Compatibility Check ---

[CRITICAL] B200 requires PyTorch with SM_100 (compute capability 10.0) support
[CRITICAL] Standard PyTorch releases do NOT support B200 - need nightly or NGC builds

[SKIP] PyTorch not available or check failed

--- TensorFlow ---

[SKIP] TensorFlow not available

--- JAX ---

[SKIP] JAX not available

--- vLLM Blackwell Support ---

[INFO] vLLM on B200 requires NGC PyTorch or nightly builds
[INFO] Recent vLLM includes CUTLASS attention (3.6x faster on B200)

[SKIP] vLLM not available

--- TensorRT / TensorRT-LLM ---

TensorRT import failed: No module named 'tensorrt'
TensorRT-LLM not found

--- FlashAttention / FlashInfer (Blackwell Optimized) ---

flash-attn not installed
flashinfer not installed (provides Blackwell-optimized attention)

--- Other ML Libraries ---

Installed ML libraries:

--- Full Pip Package List ---

[CMD] Pip list: pip3 list
Package            Version
------------------ -------------
attrs              23.2.0
Babel              2.10.3
bcc                0.29.1
blinker            1.7.0
boto3              1.34.46
botocore           1.34.46
certifi            2023.11.17
chardet            5.2.0
cloud-init         25.2
command-not-found  0.3
configobj          5.0.8
cryptography       41.0.7
dbus-python        1.3.2
distlib            0.3.8
distro             1.9.0
filelock           3.13.1
httplib2           0.20.4
idna               3.6
Jinja2             3.1.2
jmespath           1.0.1
jsonpatch          1.32
jsonpointer        2.0
jsonschema         4.10.3
launchpadlib       1.11.0
lazr.restfulclient 0.14.6
lazr.uri           1.0.6
markdown-it-py     3.0.0
MarkupSafe         2.1.5
mdurl              0.1.2
netaddr            0.8.0
oauthlib           3.2.2
packaging          24.0
pexpect            4.9.0
pip                24.0
platformdirs       4.2.0
ptyprocess         0.7.0
Pygments           2.17.2
PyGObject          3.48.2
PyJWT              2.7.0
pyOpenSSL          23.2.0
pyparsing          3.1.1
pyrsistent         0.20.0
pyserial           3.5
python-apt         2.7.7+ubuntu5
python-dateutil    2.8.2
python-magic       0.4.27
pytz               2024.1
PyYAML             6.0.1
requests           2.31.0
rich               13.7.1
s3transfer         0.10.1
setuptools         68.1.2
six                1.16.0
sos                4.8.2
ssh-import-id      5.11
typing_extensions  4.10.0
ufw                0.36.2
urllib3            2.0.7
virtualenv         20.25.0+ds
wadllib            1.3.6
wheel              0.42.0


===============================================================================
  PHASE 8: CONTAINER AND ORCHESTRATION
  2025-12-18 20:54:20
===============================================================================


--- Docker ---

[CMD] Docker version: docker version
Client: Docker Engine - Community
 Version:           28.5.1
 API version:       1.51
 Go version:        go1.24.8
 Git commit:        e180ab8
 Built:             Wed Oct  8 12:17:26 2025
 OS/Arch:           linux/amd64
 Context:           default
permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.51/version": dial unix /var/run/docker.sock: connect: permission denied
[WARN] Command returned non-zero exit code

[CMD] Docker info: docker info
Client: Docker Engine - Community
 Version:    28.5.1
 Context:    default
 Debug Mode: false
 Plugins:
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.29.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose (Docker Inc.)
    Version:  v2.40.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.51/info": dial unix /var/run/docker.sock: connect: permission denied
[WARN] Command returned non-zero exit code

[SKIP] File/dir not found: /etc/docker/daemon.json

[CHECK] Docker default runtime:
[CMD] Docker images: docker images
permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Head "http://%2Fvar%2Frun%2Fdocker.sock/_ping": dial unix /var/run/docker.sock: connect: permission denied
[WARN] Command returned non-zero exit code

[CMD] Running containers: docker ps
permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.51/containers/json": dial unix /var/run/docker.sock: connect: permission denied
[WARN] Command returned non-zero exit code


--- Podman (Alternative Container Runtime) ---

[CMD] Podman version: podman version
[SKIP] Command not found: podman

[CMD] Podman info: podman info
[SKIP] Command not found: podman


--- Kubernetes ---

[CMD] kubectl version: kubectl version --client
[SKIP] Command not found: kubectl


--- Slurm ---

[CMD] Slurm version: sinfo --version
[SKIP] Command not found: sinfo

[CMD] Slurm nodes: sinfo
[SKIP] Command not found: sinfo


===============================================================================
  PHASE 9: PERFORMANCE BASELINE TESTS
  2025-12-18 20:54:21
===============================================================================


--- Disk I/O Baseline (Model Loading Speed) ---

[INFO] Testing disk write/read speed (affects model loading time)



--- GPU Utilization Baseline ---

[CMD] GPU stats 5 samples: nvidia-smi dmon -c 5 -s pucvmet
# gpu    pwr  gtemp  mtemp     sm    mem    enc    dec    jpg    ofa   mclk   pclk  pviol  tviol     fb   bar1   ccpm  sbecc  dbecc    pci  rxpci  txpci 
# Idx      W      C      C      %      %      %      %      %      %    MHz    MHz      %   bool     MB     MB     MB   errs   errs   errs   MB/s   MB/s 
    0    144     30     30      0      0      0      0      0      0   3996    120      0      0      0      1      0      0      0      0      0      2 
    0    144     30     30      0      0      0      0      0      0   3996    120      0      0      0      1      0      0      0      0      0      0 
    0    144     30     30      0      0      0      0      0      0   3996    120      0      0      0      1      0      0      0      0      0      2 
    0    144     30     30      0      0      0      0      0      0   3996    120      0      0      0      1      0      0      0      0      0      0 
    0    144     30     30      0      0      0      0      0      0   3996    120      0      0      0      1      0      0      0      0      0      2 


--- GPU Memory Bandwidth Test ---

[SKIP] GPU bandwidth test failed

--- FP16 Matrix Multiplication (Transformer Workload) ---

[SKIP] MatMul test failed

--- NVLink Bandwidth Test (Multi-GPU) ---

[SKIP] NVLink test failed

===============================================================================
  PHASE 10: ADDITIONAL DISCOVERY
  2025-12-18 20:54:26
===============================================================================


--- Pre-loaded Models ---

[CMD] Hugging Face cache: ls -la /home/ubuntu/.cache/huggingface/
ls: cannot access '/home/ubuntu/.cache/huggingface/': No such file or directory
[WARN] Command returned non-zero exit code

[CMD] HF hub models: ls /home/ubuntu/.cache/huggingface/hub/
ls: cannot access '/home/ubuntu/.cache/huggingface/hub/': No such file or directory
[WARN] Command returned non-zero exit code

[CMD] Torch hub cache: ls -la /home/ubuntu/.cache/torch/
ls: cannot access '/home/ubuntu/.cache/torch/': No such file or directory
[WARN] Command returned non-zero exit code


--- Lambda Stack Specific ---

[CMD] Lambda Stack packages: dpkg -l
[SKIP] File/dir not found: /etc/lambda-stack-version


--- Brev Specific ---

[CMD] Brev CLI: brev version
[SKIP] Command not found: brev

[CMD] Brev workspace info: brev ls
[SKIP] Command not found: brev

[SKIP] File/dir not found: /home/ubuntu/.brev/config.yaml

[CMD] Brev agent: pgrep -a brev
[WARN] Command returned non-zero exit code


--- Jupyter Environment ---

[CMD] JupyterLab: jupyter lab --version
[SKIP] Command not found: jupyter

[CMD] Jupyter kernels: jupyter kernelspec list
[SKIP] Command not found: jupyter


--- System Services (GPU-related) ---

[CMD] GPU services: systemctl list-units --type=service
  docker.service                                 loaded active running Docker Application Container Engine
  nvidia-persistenced.service                    loaded active running NVIDIA Persistence Daemon

--- Kernel Modules ---

[CMD] Loaded nvidia modules: lsmod
nvidia_modeset       1724416  0
video                  77824  1 nvidia_modeset
nvidia_uvm           2117632  0
nvidia_peermem         16384  0
nvidia              11653120  8 nvidia_uvm,nvidia_peermem,nvidia_modeset
ib_uverbs             200704  3 nvidia_peermem,rdma_ucm,mlx5_ib
111

--- System Limits ---

[CMD] ulimit -a: ulimit -a
real-time non-blocking time  (microseconds, -R) unlimited
core file size              (blocks, -c) 0
data seg size               (kbytes, -d) unlimited
scheduling priority                 (-e) 0
file size                   (blocks, -f) unlimited
pending signals                     (-i) 1449776
max locked memory           (kbytes, -l) unlimited
max memory size             (kbytes, -m) unlimited
open files                          (-n) 1024
pipe size                (512 bytes, -p) 8
POSIX message queues         (bytes, -q) 819200
real-time priority                  (-r) 0
stack size                  (kbytes, -s) 8192
cpu time                   (seconds, -t) unlimited
max user processes                  (-u) 1449776
virtual memory              (kbytes, -v) unlimited
file locks                          (-x) unlimited

[CMD] Max open files: cat /proc/sys/fs/file-max
9223372036854775807


--- Instance Metadata (Cloud) ---

[CMD] Cloud provider metadata: curl -s --connect-timeout 2 http://169.254.169.254/latest/meta-data/
<html>
<head><title>404 Not Found</title></head>
<body bgcolor="white">
<center><h1>404 Not Found</h1></center>
</body>
</html>


===============================================================================
  DISCOVERY COMPLETE
  2025-12-18 20:54:26
===============================================================================


===============================================================================
  DISCOVERY COMPLETE
  Finished at: Thu Dec 18 20:54:26 UTC 2025
  Log file: /home/ubuntu/b200_discovery_192-9-185-148_20251218_205418.log
===============================================================================

=== QUICK SUMMARY ===

System: 192-9-185-148 - 6.11.0-1016-nvidia
OS: Ubuntu 24.04.3 LTS

name, memory.total [MiB], driver_version
NVIDIA B200, 183359 MiB, 570.195.03

CUDA Toolkit: 
PyTorch: N/A
Python: 3.12.3

=== B200 BLACKWELL VALIDATION ===
[CHECK] Verify nvidia-open driver
[CHECK] Fabric Manager status
[CHECK] PyTorch installation

Log saved to: /home/ubuntu/b200_discovery_192-9-185-148_20251218_205418.log
To compare instances: diff <log1> <log2>
